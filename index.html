<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="icon" type="image/png" href="assets/icon.png" />
  <title>ECHO</title>
  <meta name="description" content="TODO">
  <meta name="keywords" content="unified model, image generation benchmark, native multimodal model">

  <meta property="og:type" content="website">
  <meta property="og:title" content="ECHO">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZDTLD0T399"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-ZDTLD0T399');
  </script>

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <!-- popper used for tooltips -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <!-- bootstrap styling used for carousel -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/custom.css">

  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet"/>
  <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@300;400;600;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Comic+Neue:wght@300;400;600;700&display=swap" rel="stylesheet">
  
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/interactions.js"></script>

  <style>
    body {
        font-family: 'Inter', sans-serif;
    }
  </style>

</head>
<body>

<section class="hero">
  <div class="hero-body" style="padding: 3rem 1.5rem 0.5rem 1.5rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title publication-title serif-header">
    			  Constantly Improving Image Models Need<br> 
    			  Constantly Improving Benchmarks
    		  </h1>
          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="https://jiaxin.ge" target="_blank">Jiaxin Ge</a><sup>*</sup>
            </span>
            <span class="author-block">
              <a href="https://people.eecs.berkeley.edu/~graceluo" target="_blank">Grace Luo</a><sup>*</sup>
            </span>
            <br>
            <span class="author-block">
              Heekyung Lee
            </span>
            <span class="author-block">
              Nishant Malpani
            </span>
            <span class="author-block">
              Long Lian
            </span>
            <span class="author-block">
              XuDong Wang
            </span>
            <br>
            <span class="author-block">
              <a href="https://holynski.org/" target="_blank">Aleksander Holynski</a>
            </span> 
            <span class="author-block">
              <a href="http://people.eecs.berkeley.edu/~trevor" target="_blank">Trevor Darrell</a>
            </span>  
            <span class="author-block">
              <a href="https://www.sewonmin.com" target="_blank">Sewon Min</a>
            </span>  
            <span class="author-block">
              <a href="https://dchan.cc" target="_blank">David M. Chan</a>
          </div>
          <div class="is-size-7 publication-authors" style="margin-top: 20px;">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>
          <br>
          <div class="is-size-6 publication-authors">
            <span class="author-block">UC Berkeley</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-dark" style="box-shadow: 3px 3px 0px black;">
                  <span class="icon">
                      <i class="fa fa-database"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="" target="_blank" class="external-link button is-normal is-dark" style="box-shadow: 3px 3px 0px black;">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <div class="is-centered has-text-centered">
      <p>
        <b>TL;DR:</b> The newest in-the-wild image generation benchmark.
      </p>
      <br>
      <div class="max-width-content">
        <video id="teaser" muted playsinline onclick="playVideo('teaser')" style="max-width: min(70vw, 500px);">
          <source src="assets/teaser.m4v" type="video/mp4">
        </video>
        <br>
        <button class="button is-white btn-teaser" onclick="playVideo('teaser')">
          <img style="margin-right: 5px;" src="assets/hand.svg" />
          Click to animate figure
        </button>
      </div>
    </div>
  </div>
</section>
<!-- Abstract -->

<!-- Method -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4 serif-header">Abstract</h2>
        <div class="content has-text-left">
          <p>
            Recent advances in image generation, often driven by proprietary systems like GPT-4o Image Gen, regularly introduce new capabilities that reshape how users interact with these models. Existing benchmarks often lag behind and fail to capture these emerging use cases, leaving a gap between community perceptions of progress and formal evaluation. To address this, we present <span class="echo">ECHO</span>, a framework for constructing benchmarks directly from real-world evidence of model use: social media posts that showcase novel prompts and qualitative user judgments. Applying this framework to GPT-4o Image Gen, we construct a dataset of over 35,000 prompts curated from such posts. Our analysis shows that <span class="echo">ECHO</span> (1) discovers creative and complex tasks absent from existing benchmarks, such as re-rendering product labels across languages or generating receipts with specified totals, (2) more clearly distinguishes state-of-the-art models from alternatives, and (3) surfaces community feedback that we use to inform the design of metrics for model quality (e.g., measuring observed shifts in color, identity, and structure).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Method -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4 serif-header">ECHO: Extracting Community Hatched Observations</h2>
        <br>
        <div class="max-width-content">
          <img src="assets/approach.jpg" />
        </div>
        <br>
        <div class="content has-text-left">
          <p>
            The <span class="echo">ECHO</span> framework is motivated by several challenges inherent to social media. (1) We start with broad queries followed by relevance filtering, since basic querying presents a volume-relevance tradeoff. (2) We then extract prompts from these posts, making sure to utilize the full post tree, as context can be spread across posts. (3) We then apply multimodal processing, since useful data also exists in non-standard formats. (4) Finally, we reserve the highest quality data for benchmarking, while the rest is used for analysis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Method -->

<!-- Dataset Comparison -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-4 serif-header">Dataset Comparison</h2>
        <div id="select-dataset-comparison" class="select-row">
          <span>
            Split:
            <select onchange="changePlotly('dataset-comparison')">
              <option value="text_to_image">Text-to-Image</option>
              <option value="image_to_image">Image-to-Image</option>
            </select>
          </span>
        </div>
        <div style="padding-top: 5px; color: #C7C7C7;">
          <img style="width: 20px; margin-top: -3px;" src="assets/info.svg" />
          Select from the dropdown above then hover over the plot
        </div>
        <div style="max-width:550px;overflow:auto; margin:0 auto;">
          <iframe id="dataset-comparison-frame" src="assets/dataset_comparison/task_vector/text_to_image.html" style="border:none; width:100%; height:530px;">
          </iframe>
        </div>
        <div class="content has-text-left">
          <p>
            The prompts in the <span class="echo">ECHO</span> dataset are more diverse and better resemble natural user language than prior datasets.
            Above, we show a <a href="https://lvdmaaten.github.io/tsne" target="_blank">t-SNE</a> visualization comparing the prompts from <span class="echo">ECHO</span> and prior text-to-image [<a href="https://arxiv.org/abs/2310.11513" target="_blank">1</a>, <a href="https://arxiv.org/abs/2304.05977" target="_blank">2</a>, <a href="https://arxiv.org/abs/2305.01569" target="_blank">3</a>] or image-to-image [<a href="https://step1x-edit.github.io" target="_blank">4</a>, <a href="https://github.com/timothybrooks/instruct-pix2pix" target="_blank">5</a>, <a href="https://osu-nlp-group.github.io/MagicBrush" target="_blank">6</a>] datasets. Hover over each point to see prompts from each dataset!
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Dataset Comparison -->

<!-- Community Feedback -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-4 serif-header">Community Feedback</h2>
        <div style="padding-top: 5px; color: #C7C7C7;">
          <img style="width: 20px; margin-top: -3px;" src="assets/info.svg" />
          Hover over the word cloud to see examples
        </div>
        <br>
        <div style="max-width:420px; overflow:auto; margin:0 auto;">
          <iframe id="post-volume-frame" src="assets/community_feedback.html" style="border:none; width:100%; height:420px;">
          </iframe>
        </div>
        <br>
        <div class="content has-text-left">
          <p>
            <span class="echo">ECHO</span> not only extracts image generation prompts but also community feedback. We visualize a word cloud of common failures discussed in this feedback, which cover both practical capabilities that affect real-world usability as well as curiosity-driven tests that reveal deeper model limitations. Hover over each word to see example failures!
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Community Feedback -->

<!-- Overall Evaluation -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-4 serif-header">Overall Evaluation</h2>
        <div style="display: flex; justify-content: center;">
          <img id="" src="" style="max-width: 70%;">
        </div>
        <div class="content has-text-left">
          <p>
            TODO
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Overall Evaluation -->

<!-- Specialized Metrics -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-4 serif-header">Specialized Metrics from Community Feedback</h2>
        <div id="select-specialized-metrics" class="select-row">
          <span>
            Metric:
            <select onchange="changeImage('specialized-metrics')">
              <option value="color_shift">Color Shift Magnitude</option>
              <option value="face_identity">Face Identity Similarity</option>
              <option value="structure_distance">Structure Distance</option>
              <option value="text_rendering">Text Rendering Accuracy</option>
            </select>
          </span>
        </div>
        <div style="padding-top: 5px; color: #C7C7C7;">
          <img style="width: 20px; margin-top: -3px;" src="assets/info.svg" />
          Select from the dropdown to see each metric
        </div>
        <br>
        <div style="display: flex; justify-content: center;">
          <img id="specialized-metrics" src="assets/specialized_metrics/color_shift.jpg" style="max-width: 70%;">
        </div>
        <div class="content has-text-left">
          <p>
            TODO
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Specialized Metrics -->

<!-- Post Volume -->
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-4 serif-header">Post Volume</h2>
        <div style="padding-top: 5px; color: #C7C7C7;">
          <img style="width: 20px; margin-top: -3px;" src="assets/info.svg" />
          Hover over the plot to see counts
        </div>
        <br>
        <div style="max-width:630px; overflow:auto; margin:0 auto;">
          <iframe id="post-volume-frame" src="assets/post_volume.html" style="border:none; width:100%; height:330px;">
          </iframe>
        </div>
        <div class="content has-text-left">
          <p>
            Since the <span class="echo">ECHO</span> framework operates on a large-scale, it can give insight into activity surrounding a model of interest.
            We plot the posts captured by our framework, after running all steps including relevance and quality filtering.
            We mark spikes in activity in yellow, including the day after the 4o Image Gen model release (<a href="https://openai.com/index/introducing-4o-image-generation" target="_blank">Mar 26</a>), the day of the o3 model release (<a href="https://openai.com/index/introducing-o3-and-o4-mini" target="_blank">Apr 16</a>), and the day after the 4o Image Gen API release (<a href="https://openai.com/index/image-generation-api" target="_blank">Apr 24</a>).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- Post Volume -->

<!-- Acknowledgements and Citation -->
<hr>
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title is-4 serif-header">Acknowledgements</h2>
    <p>
      We thank Stephanie Fu, Michelle Li, and Alexander Pan for their helpful feedback.
      We also thank the folks at Stochastic Labs for previewing early prototypes of this work. Finally, we extend a special thank you to Lisa Dunlap for entertaining many extensive discussions on evaluations.
    </p>
    <h2 class="title is-4 serif-header">BibTeX</h2>
    <pre><code>
    @article{ge2025echo,
      title={Constantly Improving Image Models Need Constantly Improving Benchmarks},
      author={Jiaxin Ge, Grace Luo, Heekyung Lee, Nishant Malpani, Long Lian, XuDong Wang, Aleksander Holynski, Trevor Darrell, Sewon Min, David M. Chan},
      journal={arXiv},
      year={2025}
    }
    </code></pre>
  </div>
</section>
<!-- Acknowledgements and Citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template is based on the
            <a href="https://nerfies.github.io">Nerfies</a>
            and <a href="https://dual-process.github.io">Dual-Process Image Generation</a> project pages.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
