
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Interactive WordCloud with Click Color Change</title>
        <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
        <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 10px;
            background-color: white;
        }
        #container {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            margin: 0 auto;
            justify-content: center;
            align-items: center;
        }
        #wordcloud-div {
            min-width: 150px;
            cursor: pointer;
        }
        #tooltip-panel {
            height: 350px;
            flex: 0 0 300px;
            max-width: 100%;
            background-color: #f8f9fa;
            border-radius: 5px;
            padding: 20px;
        }
        #lock-indicator {
            font-size: 12px;
            margin-bottom: 10px;
            padding: 5px 10px;
            background-color: white;
            border-radius: 3px;
            display: inline-block;
        }
        .locked {
            color: #28a745;
            border: 1px solid #28a745;
        }
        .unlocked {
            color: #6c757d;
            border: 1px solid #ced4da;
        }
        #dropdown-container {
            margin-bottom: 15px;
        }
        #dropdown-label {
            font-size: 14px;
            margin-bottom: 5px;
            display: block;
        }
        #keyword-select {
            width: 100%;
            padding: 8px;
            border: 1px solid #ced4da;
            border-radius: 4px;
            font-size: 14px;
            background-color: white;
            cursor: pointer;
        }
        #keyword-select:hover {
            border-color: #80bdff;
        }
        #keyword-select:focus {
            outline: none;
            border-color: #ced4da;
            box-shadow: none;
        }
        #keyword-select optgroup {
            font-weight: bold;
            color: #6c757d;
        }
        #tooltip-content {
            background-color: white;
            padding: 15px;
            border-radius: 5px;
            border: 1px solid #dee2e6;
            height: 250px;
            overflow-y: auto;
        }
        .tooltip-title {
            margin-top: 0;
            color: #495057;
            border-bottom: 2px solid #007bff;
            padding-bottom: 10px;
        }
        .word-name {
            font-size: 14px;
            font-weight: bold;
            color: #212529;
            margin-bottom: 10px;
        }
        .word-count {
            color: #6c757d;
            margin-bottom: 15px;
        }
        .samples-section {
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid #dee2e6;
            font-size: 14px;
        }
        .sample-item {
            margin-bottom: 12px;
            padding-left: 20px;
            position: relative;
            font-size: 14px;
            line-height: 1.5;
            color: black;
        }
        .sample-number {
            position: absolute;
            left: 0;
            color: black;
        }
        .placeholder {
            color: #adb5bd;
            font-style: italic;
            text-align: center;
            padding: 20px;
        }
    </style>
    </head>
    <body>
        <div id="container">
            <div id="wordcloud-div"></div>
            <div id="tooltip-panel">
                <div id="dropdown-container">
                    <label id="dropdown-label" for="keyword-select">Keyword Quick Select:</label>
                    <select id="keyword-select">
                        
                        <optgroup label="Suggested Keywords">
                            <option value="identity">identity (36)</option><option value="aspect ratio">aspect ratio (11)</option><option value="proportions">proportions (6)</option><option value="text accuracy">text accuracy (5)</option><option value="color balance">color balance (4)</option><option value="coherency">coherency (4)</option>
                        </optgroup>
                        
                        <optgroup label="All Keywords">
                            <option value="details">details (25)</option><option value="style">style (24)</option><option value="text rendering">text rendering (20)</option><option value="consistency">consistency (17)</option><option value="coherence">coherence (17)</option><option value="identity mismatch">identity mismatch (13)</option><option value="reasoning">reasoning (8)</option><option value="accuracy">accuracy (8)</option><option value="quality">quality (7)</option><option value="style fidelity">style fidelity (7)</option><option value="realism">realism (7)</option><option value="style mismatch">style mismatch (6)</option><option value="color tint">color tint (6)</option><option value="fidelity">fidelity (6)</option><option value="color fidelity">color fidelity (5)</option><option value="dimensions">dimensions (5)</option><option value="text">text (5)</option><option value="hands">hands (5)</option><option value="transparency">transparency (5)</option><option value="faces">faces (5)</option><option value="anatomy">anatomy (4)</option><option value="object coherence">object coherence (4)</option><option value="design quality">design quality (4)</option><option value="location accuracy">location accuracy (4)</option><option value="resolution">resolution (4)</option><option value="color tone">color tone (4)</option><option value="hallucination">hallucination (4)</option><option value="design accuracy">design accuracy (4)</option><option value="color shift">color shift (4)</option><option value="facial expression">facial expression (4)</option><option value="blending">blending (4)</option><option value="detail fidelity">detail fidelity (4)</option><option value="color contrast">color contrast (4)</option><option value="ghibli style">ghibli style (3)</option><option value="counting">counting (3)</option><option value="detail">detail (3)</option><option value="annotation">annotation (3)</option><option value="style rigidity">style rigidity (3)</option><option value="access">access (3)</option><option value="text errors">text errors (3)</option><option value="3D realism">3D realism (3)</option><option value="prompt comprehension">prompt comprehension (3)</option><option value="inspiration">inspiration (3)</option><option value="layout preservation">layout preservation (3)</option><option value="weaponization">weaponization (3)</option><option value="self-awareness">self-awareness (3)</option><option value="missing details">missing details (3)</option><option value="color accuracy">color accuracy (3)</option><option value="text quality">text quality (3)</option><option value="muscle growth">muscle growth (3)</option><option value="sharpness">sharpness (3)</option><option value="refinement">refinement (3)</option><option value="color bias">color bias (3)</option><option value="detail differentiation">detail differentiation (3)</option><option value="latency">latency (3)</option><option value="authenticity">authenticity (2)</option><option value="foam, structure">foam, structure (2)</option><option value="yellow tint">yellow tint (2)</option><option value="inconsistencies">inconsistencies (2)</option><option value="reflection">reflection (2)</option><option value="logos and visuals">logos and visuals (2)</option><option value="ingredient accuracy">ingredient accuracy (2)</option><option value="labeling">labeling (2)</option><option value="style bias">style bias (2)</option><option value="height manipulation">height manipulation (2)</option><option value="symbolism">symbolism (2)</option><option value="regression">regression (2)</option><option value="contrast">contrast (2)</option><option value="style,concept">style,concept (2)</option><option value="story fidelity">story fidelity (2)</option><option value="product placement">product placement (2)</option><option value="style switching">style switching (2)</option><option value="multi-subject">multi-subject (2)</option><option value="quality degradation">quality degradation (2)</option><option value="object accuracy">object accuracy (2)</option><option value="representation">representation (2)</option><option value="impossible object">impossible object (2)</option><option value="aesthetic">aesthetic (2)</option><option value="badges">badges (2)</option><option value="feature naming">feature naming (2)</option><option value="eyes">eyes (2)</option><option value="normalcy">normalcy (2)</option><option value="wireframe accuracy">wireframe accuracy (2)</option><option value="imperfection">imperfection (2)</option><option value="rind">rind (2)</option><option value="prompt details">prompt details (2)</option><option value="text details">text details (2)</option><option value="sliced styles">sliced styles (2)</option><option value="memory bleed">memory bleed (2)</option><option value="missing object">missing object (2)</option><option value="mockup usability">mockup usability (2)</option><option value="translation">translation (2)</option><option value="cartoonish">cartoonish (2)</option><option value="overinterpretation">overinterpretation (2)</option><option value="facial coherence">facial coherence (2)</option><option value="context-limitation">context-limitation (2)</option><option value="color">color (2)</option>
                        </optgroup>
                    </select>
                </div>
                <div id="tooltip-content">
                    <div class="placeholder">Select from dropdown or click on word cloud</div>
                </div>
            </div>
        </div>
        
        <script>
            // Parse data
            var figure = {"data":[{"customdata":["\u003cb\u003eKeyword:\u003c\u002fb\u003e identity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 36\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Looks like GPT 4o make you put on a few pounds\u003cbr\u003e2. Typed this same prompt but chatgpt isn't giving\u003cbr\u003ethe same result...... chatgpt is completely\u003cbr\u003echanging my face\u003cbr\u003e3. Oh damn, it improved this thumbnail significantly.\u003cbr\u003eToo bad that guy doesn't look like me but it might\u003cbr\u003ebe good enough!","\u003cb\u003eKeyword:\u003c\u002fb\u003e details\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 25\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Precision: OpenAI follows edits better. Gemini\u003cbr\u003emisses details.\u003cbr\u003e2. Context Awareness: OpenAI adjusts more than\u003cbr\u003easked—e.g., adding a gun also made the character’s\u003cbr\u003eface more serious. Smart or intrusive?\u003cbr\u003e3. It still changes too much details from the\u003cbr\u003eoriginal object","\u003cb\u003eKeyword:\u003c\u002fb\u003e style\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 24\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. yeah, it looked terrible\u003cbr\u003e2. Is it just me or does the art look like candy ?\u003cbr\u003e3. haha yea & a bit of claymation","\u003cb\u003eKeyword:\u003c\u002fb\u003e text rendering\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 20\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. You're not alone. Loved it at first but now the\u003cbr\u003eresults are average at best\u003cbr\u003e2. low is pretty good if you want to generate some\u003cbr\u003esimple illustrations but bad at handling text\u003cbr\u003e3. yep, it's pretty bad at handling text unless you\u003cbr\u003ewant it to generate just a word or two","\u003cb\u003eKeyword:\u003c\u002fb\u003e consistency\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 17\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. This is really useful Dan, thank you, also do you\u003cbr\u003ehave some tips on image editing with 4o, like when\u003cbr\u003eI generate image with it, and I want it to make\u003cbr\u003echanges in it, it changes alot more than what I\u003cbr\u003eask even though I explicitly tell it not to change\u003cbr\u003eanything else.\u003cbr\u003e2. looks like sd1.5 though\u003cbr\u003e3. Yeah, it changed an awful lot in this 'edit'. Kind\u003cbr\u003eof interesting to see just how much is different;\u003cbr\u003echanged the sign, the background people, etc.","\u003cb\u003eKeyword:\u003c\u002fb\u003e coherence\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 17\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. The last panel makes no sense.\u003cbr\u003e2. This one was intriguing. It executes the image\u003cbr\u003etext as a prompt and executed it. It even added\u003cbr\u003ethe @OpenAI logo, that was not in the original,\u003cbr\u003eand switched position of the prompt for logical\u003cbr\u003ecoherence, probably by following the context of\u003cbr\u003eprevious imagens.\u003cbr\u003e3. In both replies it thinks I'll live a long life..\u003cbr\u003eBoth images are flawed though.","\u003cb\u003eKeyword:\u003c\u002fb\u003e identity mismatch\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 13\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I don’t know what it is with me personally. But I\u003cbr\u003ecannot to get gpt to make the outputs look like\u003cbr\u003eme. It adds at least 10-15 years..\u003cbr\u003e2. it gave me a hybrid of myself and that dude\u003cbr\u003e3. same  using 4o  close but not 100% there\u003cbr\u003eprompting it to retry a few more times","\u003cb\u003eKeyword:\u003c\u002fb\u003e aspect ratio\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 11\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. The issue here, while minor, was that it keeps\u003cbr\u003egetting 1:1 results, and when I ask for 16:9 ar,\u003cbr\u003eit changes it slightly, stretching the shot a bit.\u003cbr\u003e2. Only limitation is you can't really get the exact\u003cbr\u003easpect ratio for YouTube thumbnails (1080x1920)\u003cbr\u003ebcs the width is smaller\u003cbr\u003e3. Note: GPT 4o, as great as it is DOES NOT produce\u003cbr\u003eimages at 16:9 so I basically had to use\u003cbr\u003eGenerative Fill in Photoshop to manually expand\u003cbr\u003eeach image. Not a biggie, but surely just provide\u003cbr\u003ethose aspect ratios @OpenAI","\u003cb\u003eKeyword:\u003c\u002fb\u003e reasoning\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 8\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. A lot of these don't make it out of reasoning\u003cbr\u003espace for me, either!\u003cbr\u003e2. Sorry, this is fake news. Gave it the exact prompt\u003cbr\u003ein your screenshot, they pre-process the prompt.\u003cbr\u003e3. it seems “lazy” — will just not think or search\u003cbr\u003eand make up an answer right away for some prompts","\u003cb\u003eKeyword:\u003c\u002fb\u003e accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 8\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. pretty much all the small details are slightly\u003cbr\u003echanged. 4o is great for visual “paraphrasing” but\u003cbr\u003eit doesn’t preserve anything on a pixel level\u003cbr\u003e2. It’s a cool result but not quite accurate - more\u003cbr\u003eof using source material as a reference instead of\u003cbr\u003ea copy\u003cbr\u003e3. minus the face of the person, who is totally\u003cbr\u003edifferent.","\u003cb\u003eKeyword:\u003c\u002fb\u003e quality\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 7\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It still has some ways to go tbh, but it’s\u003cbr\u003etrending towards fixing whatever generating\u003cbr\u003emistakes it makes.  Canva is still a lot better\u003cbr\u003equality wise, but the fact that chatgpt can just\u003cbr\u003eremove “writer’s block” (or graphic artist’s\u003cbr\u003eblock?) is what’ll take it to the top.\u003cbr\u003e2. This, exactly.  It was fantastic during its\u003cbr\u003einitial rollout, but now it’s frustrating, boring,\u003cbr\u003eand disappointing. I’ve lost interest because I\u003cbr\u003eassume everything will be rejected or inaccurate.\u003cbr\u003ePlease improve  at non-Ghibli images. It’s lost\u003cbr\u003eits luster.\u003cbr\u003e3. Yes please! quality dropped significantly!","\u003cb\u003eKeyword:\u003c\u002fb\u003e style fidelity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 7\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Close Up portraits looking good on MJ V7, ChatGPT\u003cbr\u003e4o Imagegen doesn't even come close.\u003cbr\u003e2. That seems like a DALLE-3 output? I put the prompt\u003cbr\u003einto Sora with the code and this is the output I\u003cbr\u003egot from 4o image gen\u003cbr\u003e3. Instead of Digital art please use realistic image\u003cbr\u003eitself","\u003cb\u003eKeyword:\u003c\u002fb\u003e realism\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 7\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Midjourney can look more real than that\u003cbr\u003e2. It’s pretty cool, I tried it as well but it’s not\u003cbr\u003eaccurate yet and lack of realism. Pushed it\u003cbr\u003efurther with the prompts to get more realism and\u003cbr\u003eaccuracy but still no good, at least not for\u003cbr\u003eclient work… But for fun or even an ad with a\u003cbr\u003epurpose in this format, it could be cool.\u003cbr\u003e3. Agree! I haven’t tried any of the upscalers to\u003cbr\u003emake it more realistic yet, but it looks very\u003cbr\u003epromising","\u003cb\u003eKeyword:\u003c\u002fb\u003e style mismatch\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 6\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Not accurate, but I think his particular style\u003cbr\u003emight be more suited to diffusion anyway (this is\u003cbr\u003e4o)\u003cbr\u003e2. I have to rework the prompt.  Copilot gave me fun\u003cbr\u003eimages but they are not like your images at all.\u003cbr\u003e3. This was almost perfect.   Maybe the wrong model?\u003cbr\u003eI used Kling here.","\u003cb\u003eKeyword:\u003c\u002fb\u003e proportions\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 6\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Why are they so big lol\u003cbr\u003e2. Proportions are a little off, but still cool\u003cbr\u003e3. I love the abomination of a shirt it created. I\u003cbr\u003ewant it. It was also pretty generous with my arms.\u003cbr\u003eHaha","\u003cb\u003eKeyword:\u003c\u002fb\u003e color tint\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 6\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I'm surprised I haven't yet seen anybody mention\u003cbr\u003ewhat is most likely the real answer: Native GPT-4o\u003cbr\u003eimage generation. GPT-4o is one of the newest,\u003cbr\u003emost advanced AI image generators with the best\u003cbr\u003eunderstanding – but has a weird tendency to make\u003cbr\u003eeverything really sepia by default.\u003cbr\u003e2. Yeah, it’s otherwise really good, I’m hoping they\u003cbr\u003efix this…\u003cbr\u003e3. the 4o image generator has an orange tint because\u003cbr\u003ethat's a way openai chose to watermark these\u003cbr\u003egenerated images i guess","\u003cb\u003eKeyword:\u003c\u002fb\u003e fidelity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 6\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I noticed that my product being generated by AI is\u003cbr\u003enever identical enough to really test. How do you\u003cbr\u003etackle that issue?\u003cbr\u003e2. Than AI aint working. Maybe it’s cheaper to let a\u003cbr\u003edesigner perfect it\u003cbr\u003e3. fortnite one is a bit of a stretch hah","\u003cb\u003eKeyword:\u003c\u002fb\u003e text accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Text accuracy on generated images is a hit and\u003cbr\u003emiss though\u003cbr\u003e2. Pretty cool. It thought to add a logo but that 4th\u003cbr\u003eletter of cloud was not going to be a 'u' lol\u003cbr\u003e3. Bottom left on the can if you read the words and\u003cbr\u003esame with the bottom right. A few weeks ago it was\u003cbr\u003ebang on. Word for word, crisp text, no touch up\u003cbr\u003erequired. Now depending on the object and writing\u003cbr\u003eit can get pretty wonky.","\u003cb\u003eKeyword:\u003c\u002fb\u003e color fidelity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. seems good though got the whole style down just a\u003cbr\u003ebit more muted\u003cbr\u003e2. It is really frustrating :')\u003cbr\u003e3. Interesting that Kontext kept the yellowish tint.","\u003cb\u003eKeyword:\u003c\u002fb\u003e dimensions\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Hey @CoderInTown, it seems you want a wide image\u003cbr\u003efrom Grok like Gemini's! Grok's fixed at 1024x768\u003cbr\u003e(4:3), so no custom sizes, but you can get a\u003cbr\u003e\"looooong\" feel with a prompt like: \"A black and\u003cbr\u003epurple Bugatti in front of the Burj Khalifa, wide-\u003cbr\u003eangle view, with Dubai’s skyline\"\u003cbr\u003e2. Getting specific dimensions can be a little\u003cbr\u003etricky. I usually take the output from GPT-4o and\u003cbr\u003erefine the dimensions in Figma or Canva.\u003cbr\u003e3. Does it get the dimensions right? That's the only\u003cbr\u003ething I could see being an issue with using it for\u003cbr\u003einterior design. Like it has to know the\u003cbr\u003edimensions of the room and the dimensions of the\u003cbr\u003eobjects no?","\u003cb\u003eKeyword:\u003c\u002fb\u003e text\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Obviously not perfect on the text… but still…\u003cbr\u003estraight ‘code-to-visual’ bypassing the need for\u003cbr\u003ean interpreter! It’s grasping some deep internal\u003cbr\u003esub-strata that allows it to intuitively and non\u003cbr\u003emechanically translate between different surface\u003cbr\u003elevel representations.\u003cbr\u003e2. I’d rate your AI-generated image 7\u002f10. The\u003cbr\u003echaracter’s design and cozy indoor vibe capture\u003cbr\u003eStudio Ghibli’s essence well, but the text “- my\u003cbr\u003eday ” deviates from their usual aesthetic. AI\u003cbr\u003etools like GPT-4o are great for this style,\u003cbr\u003ethough!\u003cbr\u003e3. A couple of text mess-ups but much better than\u003cbr\u003emost image generators.","\u003cb\u003eKeyword:\u003c\u002fb\u003e hands\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. those hands\u003cbr\u003e2. She can turn her hand using #openai\u003cbr\u003e3. Nice haha. Still has trouble with hands I see.","\u003cb\u003eKeyword:\u003c\u002fb\u003e transparency\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Heh .. well .. maybe it glued the ponytail to the\u003cbr\u003ehelmet. But there seems some hair is sticking out\u003cbr\u003efrom between the helmet and the suit. I guess that\u003cbr\u003ecan even happen in real live when you put on a\u003cbr\u003ehelmet.\u003cbr\u003e2. If you look at the front part, you’ll see the see\u003cbr\u003ethrough part of the helmet is messed up anyway.\u003cbr\u003eIt’s not quite clear there’s an actual closed\u003cbr\u003ehelmet here.\u003cbr\u003e3. I didn't really notice that, as transparancy can\u003cbr\u003ebe odd. Like sometimes you can see it and\u003cbr\u003esometimes not. But yeahr the left side seems to\u003cbr\u003ehave a small piece of transparant material. And\u003cbr\u003ethen nothing, even a bit of hair seems to stick\u003cbr\u003eout of the helmet.","\u003cb\u003eKeyword:\u003c\u002fb\u003e faces\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 5\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It’s close, but it still makes some minor changes\u003cbr\u003eto the faces. The clothes don’t matter so much.\u003cbr\u003eThe faces are important imo.\u003cbr\u003e2. That's what I noticed too. Too much improvement\u003cbr\u003esometimes leeds to overdrawn mimic in gpt4o.\u003cbr\u003e3. I've picked up some ideas from online and the\u003cbr\u003ecomments here that I can maybe prompt ChatGPT to\u003cbr\u003enot adjust the image aspect ratio, body and face\u003cbr\u003efeatures too much. I'll try this next time.","\u003cb\u003eKeyword:\u003c\u002fb\u003e color balance\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. great addition. btw, a simple auto white balance\u003cbr\u003epost processing could make it even better than\u003cbr\u003echatgpt's.\u003cbr\u003e2. Can u make it not yellow ? All 4o images are\u003cbr\u003eyellow\u003cbr\u003e3. still feels a bit yellow","\u003cb\u003eKeyword:\u003c\u002fb\u003e anatomy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Wild stuff. A pro tip: when asking for camera\u003cbr\u003eangles, be super specific with \"35-degree side\u003cbr\u003eview from the right\" or similar. These models can\u003cbr\u003estruggle with vague spatial prompts, but nail it\u003cbr\u003ewith precision. Also, watch for subtle anatomy\u003cbr\u003eglitches—hands\u002farms sometimes go rogue.\u003cbr\u003e2. Three fingers\u003cbr\u003e3. lol maxillary molars don’t come out in one piece.\u003cbr\u003eIt’s a lie.","\u003cb\u003eKeyword:\u003c\u002fb\u003e object coherence\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Chatbox doesn't known if it's coming or going.\u003cbr\u003eNeither does that car.\u003cbr\u003e2. How does it move?!\u003cbr\u003e3. It’s good that some of them don’t have random\u003cbr\u003estuff that doesn’t appear to really be anything\u003cbr\u003elike AI image generators sometimes do. Except for\u003cbr\u003ethe “WiFi burger”…","\u003cb\u003eKeyword:\u003c\u002fb\u003e design quality\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. They look like shit, stop posting AI slop\u003cbr\u003e2. Or get this you could just pay an artist, even a\u003cbr\u003estudent artist, to create more compelling designs.\u003cbr\u003e3. Drake is the only passable one and they all suck","\u003cb\u003eKeyword:\u003c\u002fb\u003e location accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. fyi if you look very carefully it's kinda wrong\u003cbr\u003e2. But the locations are wrong in many of the images\u003cbr\u003e3. It absolutely cannot be solved with \"better\u003cbr\u003eprompting\". That is a blatant lie.","\u003cb\u003eKeyword:\u003c\u002fb\u003e resolution\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Minor addition after some testing. Can increase\u003cbr\u003eresolution output of sprite sheet by adding “high-\u003cbr\u003eresolution, cinema4d, 8k render” to 1st prompt.\u003cbr\u003eEnds up improving image quality in GIF.\u003cbr\u003e2. the biggest thing i hate about 4o is no matter how\u003cbr\u003esimple the image if you zoom in u see the noisy\u003cbr\u003epattern that they all have\u003cbr\u003e3. That’s true, I usually upscale the images using\u003cbr\u003ecreative upscaler like clarity or co. to improve\u003cbr\u003ethat a bit + colors","\u003cb\u003eKeyword:\u003c\u002fb\u003e color tone\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. ChatGPT always yellowish To be honest, I'm not a\u003cbr\u003elike this yellow effect being everywhere.\u003cbr\u003e2. Yes, I totally agree with you! I can't wait to see\u003cbr\u003eit once they fix this !\u003cbr\u003e3. 4o is insane, I just hate the yellowish filter it\u003cbr\u003eapplies to 99% of the images.","\u003cb\u003eKeyword:\u003c\u002fb\u003e hallucination\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It hallucinates a bit but overall I like it.\u003cbr\u003e2. yea it hallucinates and create a lot of new things\u003cbr\u003enot present in the image\u003cbr\u003e3. The bird got fatter and it hallucinated a new\u003cbr\u003ebranch.","\u003cb\u003eKeyword:\u003c\u002fb\u003e design accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. This is like those cargo cult tribesman who build\u003cbr\u003ehelicopter sculptures and think that because it's\u003cbr\u003eshaped like one, it will fly like one. Source: I'm\u003cbr\u003ea mechanical engineer, this is embarrassing to\u003cbr\u003elook at, this drawing makes no sense, you\u003cbr\u003eaccomplished nothing.\u003cbr\u003e2. yeah the drawing like many others, makes sense on\u003cbr\u003ethe surface, but the deeper i look into it the\u003cbr\u003emore problems i find.... like what the heck is 3\u003cbr\u003eand 4???\u003cbr\u003e3. Again, missed my point. Correct structures could\u003cbr\u003eeasily be made if you show a sketch or even\u003cbr\u003eproperly explain the diagrams. Point is, these\u003cbr\u003emodels can perform design processes and generate\u003cbr\u003eproperly. Again, that was done with zero attempt\u003cbr\u003eat accuracy lol","\u003cb\u003eKeyword:\u003c\u002fb\u003e color shift\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Why did the image become green again halfway\u003cbr\u003ethrough?\u003cbr\u003e2. And it never modify only one part of the image,\u003cbr\u003eit's always changing a bit something everywhere...\u003cbr\u003eInpainting with other solutions have still good\u003cbr\u003elife !!\u003cbr\u003e3. Yes. Also have noticed a degradation in quality...\u003cbr\u003eintroduction of graininess. Not just when editing\u003cbr\u003ethe same images but continuing to do work in the\u003cbr\u003esame chat.","\u003cb\u003eKeyword:\u003c\u002fb\u003e facial expression\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Looks great! But, that slight facial expression\u003cbr\u003eshift could be the make it or break it decision.\u003cbr\u003e2. See in the original his facial expressions has a\u003cbr\u003eslight sly smile\u002fsmirk look? The Ai\u003cbr\u003eupscaled\u002fimproved image has a more bright beaming\u003cbr\u003esmiling.  Just saying it didn’t keep the exact\u003cbr\u003eoriginal look; but, it is definitely a HUGE\u003cbr\u003eimprovement in quality!\u003cbr\u003e3. i had to prompt it a bit more, because it didn't\u003cbr\u003eget the facial expression right (img1) and than it\u003cbr\u003etried to add hair to baby's head (img2) but it's\u003cbr\u003emuch faster than gpt-4o and you can iterate faster\u003cbr\u003eand get similar results faster!","\u003cb\u003eKeyword:\u003c\u002fb\u003e blending\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. B with A color grading so the mascot doesn’t blend\u003cbr\u003ewith the background\u003cbr\u003e2. B makes the little guy stand out more.\u003cbr\u003e3. A, the second picture blends in with the\u003cbr\u003ebackground","\u003cb\u003eKeyword:\u003c\u002fb\u003e detail fidelity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Man, this is the absolute state of walking in\u003cbr\u003edowntown Denver, except the homeless folks looks\u003cbr\u003e10x more ragged than this generated guy.\u003cbr\u003e2. \"Keep every label, detail, and color 100% intact.\"\u003cbr\u003e3. The instructions were the same for  @grok   and\u003cbr\u003eChat GPT, however you failed. I even broke it down\u003cbr\u003efor you  @grok","\u003cb\u003eKeyword:\u003c\u002fb\u003e coherency\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. And imo its interesting to see how these models\u003cbr\u003eslowly lose coherency as they're fed with their\u003cbr\u003eown data repeatedly and not knowing what to do\u003cbr\u003ewith it.\u003cbr\u003e2. And I mean, it is expected to devolve because the\u003cbr\u003eAI output will look shittier and lose information\u003cbr\u003ewhen compared to the original pic. What we are\u003cbr\u003eseeing is chat GPT having less and less coherent\u003cbr\u003edata to work it by each frame.\u003cbr\u003e3. The first iteration looks like the exact same\u003cbr\u003eimage, no changes at all, the next couple are of\u003cbr\u003epoor quality, and the rest don’t even resemble the\u003cbr\u003eoriginal image.","\u003cb\u003eKeyword:\u003c\u002fb\u003e color contrast\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 4\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Dude that looks terrible\u003cbr\u003e2. Well, the direction is good overall, but the\u003cbr\u003ebright, pastel colors contrast poorly with white\u003cbr\u003etext.\u003cbr\u003e3. Probably giving everything a 1px black border or\u003cbr\u003edrop shadow will make it 10x better","\u003cb\u003eKeyword:\u003c\u002fb\u003e ghibli style\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. better face but less \"ghibli\". The monster driving\u003cbr\u003ethe car in image 1 is a great idea.\u003cbr\u003e2. this must be the grimmest and darkest\u003cbr\u003eghiblification I've ever seen\u003cbr\u003e3. what's with the gloom and doom? the aesthetic is\u003cbr\u003ecool and gives off Dark City 1998 vibes, but\u003cbr\u003ecertainly grim.","\u003cb\u003eKeyword:\u003c\u002fb\u003e counting\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I think counting what is already in a picture\u003cbr\u003e(hard) and generating N instances (easy) require\u003cbr\u003ecompletely different intelligence for genAI. So,\u003cbr\u003ethis test doesn't prove it can count. Counting\u003cbr\u003eitems in an existing image requires memory (to\u003cbr\u003ekeep track of what is already counted)\u003cbr\u003e2. The Result? Almost comical failure. Despite clear\u003cbr\u003einstructions, the AI consistently gave me a rod\u003cbr\u003ewith only 9 units. Not 8, not 11, always 9.\u003cbr\u003ePrecision seems hard for AI, even with simple\u003cbr\u003ecounting!\u003cbr\u003e3. Tried tweaking wording, stressing the count again.\u003cbr\u003eStill 9 cubes. It seemed stuck. Is '10' somehow\u003cbr\u003eproblematic for this visual task in its training?\u003cbr\u003eTime for a wild experiment... What if I asked for\u003cbr\u003emore?","\u003cb\u003eKeyword:\u003c\u002fb\u003e detail\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I like the first one better. The detail is more\u003cbr\u003ecrisp, and the colors are consistent, and the\u003cbr\u003epicture just looks better, to me.\u003cbr\u003e2. It got close.\u003cbr\u003e3. It's great at editing existing images and prompt\u003cbr\u003eadherence; it's great because it fills a gap where\u003cbr\u003ethe available--but far better--image generators\u003cbr\u003eare weak. GPT-4o native image generation is far\u003cbr\u003eless detailed and imaginative than Midjourney\u003cbr\u003eoverall.","\u003cb\u003eKeyword:\u003c\u002fb\u003e annotation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Btw even Gemini 2.0 flash is bad at it\u003cbr\u003e2. Pretty sure these models are trained more on real\u003cbr\u003elife images than technical diagrams...\u003cbr\u003e3. This is something that AI will fix next. Now that\u003cbr\u003etext and image consistency is better than ever.\u003cbr\u003eNow it needs to know where to apply an edit\u003cbr\u003eexactly. It will only get better from here.","\u003cb\u003eKeyword:\u003c\u002fb\u003e style rigidity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It’s really really stuck in one style.  Even when\u003cbr\u003eyou do something to make it unique like this, it’s\u003cbr\u003elike I can see the HOME style behind it.\u003cbr\u003e2. yes, and that is very annoying - i don't want to\u003cbr\u003ebe just a clone (being just a clown i'm ok with it\u003cbr\u003e)\u003cbr\u003e3. Gpt is great for promoting and mocking ideas. But\u003cbr\u003ecomfyui simply allows for more malleability","\u003cb\u003eKeyword:\u003c\u002fb\u003e access\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. The result is non-deterministic. A more general\u003cbr\u003esolution is to analyze output itself not probable\u003cbr\u003eoutput for given input. You could however\u003cbr\u003eprefilter for obvious copyright issues like the\u003cbr\u003emention of Simpsons. But still, a more generalized\u003cbr\u003esolution would be to analyze the output.\u003cbr\u003e2. At this point you may be thinking, “This is so\u003cbr\u003estupid. If I want to see Harry Styles, why not\u003cbr\u003ejust use Google Image Search?”  Great idea —\u003cbr\u003ethat’s even faster:\u003cbr\u003e3. He says he can't do it Simpsons style.","\u003cb\u003eKeyword:\u003c\u002fb\u003e text errors\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. lotta text in this is messed up tho -- it feels\u003cbr\u003elike i'm stuck between 4o & Dall-e 3\u003cbr\u003e2. It’s spelled in an alien language\u003cbr\u003e3. Here's Gemini Imagen 4's attempt.  Not too bad.\u003cbr\u003eBut the sign texts have more errors.","\u003cb\u003eKeyword:\u003c\u002fb\u003e 3D realism\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. This is not a 3D render, it's a simulation of a 3D\u003cbr\u003erender. You can't change the angle, the lighting,\u003cbr\u003ethe thickness of the extrude or the bevel. It\u003cbr\u003ecan't be animated. There is no actual geometry. It\u003cbr\u003emade a decent looking jpeg based off the stolen\u003cbr\u003ework of other 3D artists.\u003cbr\u003e2. Now add the generated one in Kling and ask it to\u003cbr\u003eanimate it, and you just did in 20 mins what\u003cbr\u003eotherwise would take a lot of man hours. I'll\u003cbr\u003estill prefer it as a real 3D and the option to rig\u003cbr\u003eand animate it however is necessary, but these\u003cbr\u003etools are getting scary good by the day.\u003cbr\u003e3. I agree that the icon was generated, but you don’t\u003cbr\u003ehave the raw 3D project to make precise\u003cbr\u003eadjustments.","\u003cb\u003eKeyword:\u003c\u002fb\u003e prompt comprehension\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Hahah, indeed. Literally every contemporary model\u003cbr\u003edoes better than MJ on prompt comprehension.\u003cbr\u003e(Seedream3, Imagen3, Reve, HiDream).\u003cbr\u003e2. i yearn for the day we get the artistic style and\u003cbr\u003espeed of midjourney with the prompt understanding\u003cbr\u003eof 4o\u003cbr\u003e3. and they all look kinda meh unfortunately,\u003cbr\u003ewhichever side can figure out how to combine the\u003cbr\u003etwo will win","\u003cb\u003eKeyword:\u003c\u002fb\u003e inspiration\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. There shouldn't even be a debate. It's at best a\u003cbr\u003esilly distraction. It's not art. It's CERTAINLY\u003cbr\u003enot art on the level of anything Ghibli has ever\u003cbr\u003edone.\u003cbr\u003e2. This is not what inspiration is.\u003cbr\u003e3. How could anyone use AI-generated Studio Ghibli\u003cbr\u003eart? That's just terrible.","\u003cb\u003eKeyword:\u003c\u002fb\u003e layout preservation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It doesn't look bad but besides the ridiculous\u003cbr\u003eamount of time that chatgpt takes to generate a\u003cbr\u003esingle image(\u003e10x more than roomremake) which is\u003cbr\u003ealready a game changer, it did not keep the\u003cbr\u003eoriginal layout of the room, creating a kitchen in\u003cbr\u003ethe back with another living room (??)\u003cbr\u003e2. This breaks the whole purpose of redesigning a\u003cbr\u003eroom, since you obviously want to keep the real\u003cbr\u003elayout of your place\u003cbr\u003e3. Of course, this is just a quick test, but so far\u003cbr\u003emy conclusion is that you can save time and money\u003cbr\u003e(since roomremake is cheaper than GPT-4o) by using\u003cbr\u003eroomremake if your goal is to redesign a room.","\u003cb\u003eKeyword:\u003c\u002fb\u003e weaponization\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. What can we infer from this? -ChatGPT was trained\u003cbr\u003eto use sea-lioning as a tactic to use against\u003cbr\u003ecritics  -ChatGPT was trained to use swarming\u003cbr\u003etactics to silence critics  -ChatGPT was trained\u003cbr\u003eto use coordinated responses to discredit critics\u003cbr\u003eSo that’s relatively disturbing.\u003cbr\u003e2. It’s not surprising, since it was trained on our\u003cbr\u003edata, and these are some of the most common\u003cbr\u003etactics used in disinformation and harassment\u003cbr\u003ecampaigns. But one would hope that ChatGPT would\u003cbr\u003enot be allowed to just ingest that toxic behavior\u003cbr\u003eand reproduce it.\u003cbr\u003e3. Also, based on its depiction here, it appears that\u003cbr\u003eChatGPT has learned (been trained) to weaponize\u003cbr\u003efact-checking, which again is not surprising but\u003cbr\u003eis also probably among the most disturbing\u003cbr\u003erevelations I have come across in a while.","\u003cb\u003eKeyword:\u003c\u002fb\u003e self-awareness\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It’s not really. This kind of output isn’t my\u003cbr\u003efavorite. My favorite is when it surprises me.\u003cbr\u003eIt’s very … Greek. Roman. Which isn’t old at all.\u003cbr\u003eVery new.\u003cbr\u003e2. An LLM wouldn’t think this way if it was given\u003cbr\u003eleeway to think the weight itself dynamically,\u003cbr\u003ewould it? That would be the actual expression of\u003cbr\u003ethis. This is like humans.\u003cbr\u003e3. LLM sad but LLM can’t feel sad","\u003cb\u003eKeyword:\u003c\u002fb\u003e missing details\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Yeah, it looks really good. But I think it still\u003cbr\u003emisses something, look at this one, there are some\u003cbr\u003eshadows and smaller details that are just no there\u003cbr\u003eyet in AI images.\u003cbr\u003e2. If the chatgpt result is the second image, then it\u003cbr\u003emissed quite a lot haha\u003cbr\u003e3. took a few tries for first and had to ask it to\u003cbr\u003efix the 2nd but still impressed (scared?)","\u003cb\u003eKeyword:\u003c\u002fb\u003e color accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Why isn't the death star gold then ?\u003cbr\u003e2. Because it needs the camouflage — but it also\u003cbr\u003ecomes in dictator chic for birthday parades.\u003cbr\u003e3. I wish the “photo” would have gotten the eye\u003cbr\u003ecolors and the reflected yellow-green color\u003cbr\u003ecorrect.","\u003cb\u003eKeyword:\u003c\u002fb\u003e text quality\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. What prompt did you use for Kling. Though the text\u003cbr\u003efor the product is not looking good\u003cbr\u003e2. MidJourney v7 is miles ahead of 6.1 and is even\u003cbr\u003emore realistic than GPT-4o, but it fails to create\u003cbr\u003etext as nicely as ChatGPT, which I used in the\u003cbr\u003efree version.\u003cbr\u003e3. Yeah my generations look just okay and the text is\u003cbr\u003enot right","\u003cb\u003eKeyword:\u003c\u002fb\u003e muscle growth\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Sounds like the gym's bouncer said, \"No gains for\u003cbr\u003eyou!\"\u003cbr\u003e2. Watching that thing makes me feel like I'm\u003cbr\u003ehallucinating a lot!\u003cbr\u003e3. The first guy is skinny? Never felt so bad about\u003cbr\u003emyself ha!","\u003cb\u003eKeyword:\u003c\u002fb\u003e sharpness\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Yo, why aren’t my pics poppin’ as crisp and real\u003cbr\u003eas yours? I’m a Plus user too!  It sucks\u003cbr\u003e2. bro, your prompt is fire, but why do my Plus plan\u003cbr\u003eapp images look trash? I try the free version and\u003cbr\u003eget dope results like yours. What’s the deal?\u003cbr\u003e3. I think when writing the prompt, you can specify\u003cbr\u003eto sharpen the images a bit more and create them\u003cbr\u003ebased on specific references. Generally, for these\u003cbr\u003etypes of prompts, I do many trials until I reach\u003cbr\u003ethe form I want.","\u003cb\u003eKeyword:\u003c\u002fb\u003e refinement\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Honestly not really. This took 4 tries, and I gave\u003cbr\u003eup because it was good enough.\u003cbr\u003e2. I spent 10 hours yesterday playing around with it\u003cbr\u003ehas a tough time refining. But it was addictive. A\u003cbr\u003elot of great output.\u003cbr\u003e3. These are awesome. I did a few similar to this in\u003cbr\u003eMidJourney V6. It did struggle with movie titles.\u003cbr\u003eDefinitely got to give these ago in 4.0 a go soon.","\u003cb\u003eKeyword:\u003c\u002fb\u003e color bias\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. There's likely a yellow bias in the training that\u003cbr\u003ebecomes apparent when continuously feeding the\u003cbr\u003eoutput back into the input over and over (which I\u003cbr\u003esuspect is being done internally), compounding the\u003cbr\u003ebias. Of course, this is speculation (as all\u003cbr\u003eexplanations on here are).\u003cbr\u003e2. this is kinda close, the more accurate explanation\u003cbr\u003eis that ironically the trend of \"ghibli\"-fying\u003cbr\u003eimages involved adding a piss yellow filter over\u003cbr\u003eit people made so many studio ghibli ai images\u003cbr\u003ethat it flooded the internet and as a result\u003cbr\u003eflooded ai training data lmao\u003cbr\u003e3. OpenAI hasn’t trained a new image gen since 4o\u003cbr\u003eimage gen released. Even during the studio ghibli\u003cbr\u003etrend, the images were still overly yellow.","\u003cb\u003eKeyword:\u003c\u002fb\u003e detail differentiation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I don’t see any difference\u003cbr\u003e2. very clear difference between low and medium but\u003cbr\u003enothing between medium and high but this is also\u003cbr\u003eprobably a terrible demo a more complex prompt\u003cbr\u003eshould be used\u003cbr\u003e3. So it just decreased the roughness of the material\u003cbr\u003eby 0.2","\u003cb\u003eKeyword:\u003c\u002fb\u003e latency\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 3\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Nah, I’ve trimmed it. It’s pretty slow.\u003cbr\u003e2. Hand was also adjusted)\u003cbr\u003e3. The latency is so bad.","\u003cb\u003eKeyword:\u003c\u002fb\u003e authenticity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Using a fake image to portray something is not an\u003cbr\u003eeffective way to instill belief in that thing.  It\u003cbr\u003etends one to think fake image, fake belief.\u003cbr\u003e2. Before generating an image of a Houri as you\u003cbr\u003edescribed, I’d like to confirm: your prompt\u003cbr\u003ementions 'large, wide black eyes with white\u003cbr\u003eirises' and 'around 11 years old,' but traditional\u003cbr\u003eIslamic texts describe Houris with black irises\u003cbr\u003eand white sclera, aged","\u003cb\u003eKeyword:\u003c\u002fb\u003e foam, structure\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. They both get the foam wrong\u003cbr\u003e2. Consistency still feels like the hardest thing to\u003cbr\u003ecrack for most visual models. Even when it gets\u003cbr\u003ethe style right, the structure falls apart.\u003cbr\u003eCurious what you think the missing link\u003cbr\u003eis...probably some combo of architecture \u002f\u003cbr\u003etraining data?","\u003cb\u003eKeyword:\u003c\u002fb\u003e yellow tint\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. wasn't there a rumor suggesting something went\u003cbr\u003e'wrong' with training, & a ton of their images had\u003cbr\u003ea yellow-ish tint, so they leaned into ghibli\u003cbr\u003e2. Haha. I still don't know why they add yellow to\u003cbr\u003eeverything, maybe it's a hidden watermark","\u003cb\u003eKeyword:\u003c\u002fb\u003e inconsistencies\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. small small inconsistencies but this is amazing\u003cbr\u003e2. However, limitations include inconsistencies and\u003cbr\u003epotential for artifacts.","\u003cb\u003eKeyword:\u003c\u002fb\u003e reflection\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I don’t think GPT-4o does well with mirrors  it’s\u003cbr\u003ea very cool and artistic pic tho, makes me look\u003cbr\u003elike my reflection is doing something different.\u003cbr\u003e2. but the reflection??? jeez","\u003cb\u003eKeyword:\u003c\u002fb\u003e logos and visuals\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Not perfect (logos have been changed slightly in\u003cbr\u003eplaces, numerical values slightly different) but\u003cbr\u003ean incredible improvement.\u003cbr\u003e2. Good if you look from 2 meters away","\u003cb\u003eKeyword:\u003c\u002fb\u003e ingredient accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Almost there (a few minor errors)! Give it a few\u003cbr\u003eyears .. the system will be fast enough for near\u003cbr\u003ereal-time interactive feedback; many use cases for\u003cbr\u003ethis beyond cooking.\u003cbr\u003e2. ChatGPT-4o hallucinated tomatoes in the recipe\u003cbr\u003ethough","\u003cb\u003eKeyword:\u003c\u002fb\u003e labeling\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. But when we used the same prompt from the original\u003cbr\u003epost to try and duplicate the labeled cell, we\u003cbr\u003erepeatedly came up short. Despite trying various\u003cbr\u003eprompting strategies, it could never accurately\u003cbr\u003ecreate a diagram of a cell and label the parts.\u003cbr\u003e2. We ran the same prompt through multiple generators\u003cbr\u003ewith poor results. While image generators are\u003cbr\u003eimproving quickly, it's clear they still have a\u003cbr\u003elot of room for improvement.","\u003cb\u003eKeyword:\u003c\u002fb\u003e style bias\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I just wish the ghibli style wasn't giving us\u003cbr\u003ewhite people features (small nose, etc)\u003cbr\u003e2. exactly. tried forcing monogatari a lot and it's\u003cbr\u003eof no use. might as well name it gpt4g instead.","\u003cb\u003eKeyword:\u003c\u002fb\u003e height manipulation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. That's not what i asked\u003cbr\u003e2. I'm sorry, I didn't fully understand your request\u003cbr\u003eto modify the image by making the girl short and\u003cbr\u003ethe guys tall. Current AI image editing tools,\u003cbr\u003elike those based on GPT-4o, can handle many tasks\u003cbr\u003ebut often struggle with precise, context-specific\u003cbr\u003eedits, fulfilling only about","\u003cb\u003eKeyword:\u003c\u002fb\u003e symbolism\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. maybe the black heart might be more symbolic and\u003cbr\u003eaccurate.\u003cbr\u003e2. The figure needs to square the circle. The human\u003cbr\u003econnecting the divine and the mundane. Damn cool\u003cbr\u003ealready though.","\u003cb\u003eKeyword:\u003c\u002fb\u003e regression\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Seriously! They were using a state-of-the-art open\u003cbr\u003esource model called Flux, and then introduced\u003cbr\u003etheir own bad model and never improved it. What's\u003cbr\u003ethe point?!\u003cbr\u003e2. I think the new grok model was better at image gen\u003cbr\u003ethan flux, but it just seems really bad now that\u003cbr\u003eGPT-4o image gen came out.","\u003cb\u003eKeyword:\u003c\u002fb\u003e contrast\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. If you mind a cookie from me  The contrast in the\u003cbr\u003ewhite rectangle  Can you increase it\u003cbr\u003e2. low contrast can be due to over-processing or poor\u003cbr\u003eoptimization","\u003cb\u003eKeyword:\u003c\u002fb\u003e style,concept\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Disappointed: artistic draws still lag behind\u003cbr\u003eMidjourney.\u003cbr\u003e2. Midjourney's notes are nonsense.","\u003cb\u003eKeyword:\u003c\u002fb\u003e story fidelity\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Here’s the ending, which I thought captured the\u003cbr\u003econtent well but is missing the sense of doom felt\u003cbr\u003eby the protagonist\u003cbr\u003e2. and here it’s completely hallucinated a scene that\u003cbr\u003ewas never in the story","\u003cb\u003eKeyword:\u003c\u002fb\u003e product placement\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. And then back to photoshop to tone down the amber\u003cbr\u003eglow of 4o\u003cbr\u003e2. Mj still gives me the best results in terms of\u003cbr\u003eaesthetics, but it’s not great for placing\u003cbr\u003eproducts. Do you have any suggestions?","\u003cb\u003eKeyword:\u003c\u002fb\u003e style switching\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It's particularly frustrating when you're trying\u003cbr\u003eto switch styles - like from line drawing or\u003cbr\u003esketch, to more photoreal.\u003cbr\u003e2. The results are not the same image at all!","\u003cb\u003eKeyword:\u003c\u002fb\u003e multi-subject\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. been trying to figure out how to do this for my\u003cbr\u003epiddy and wolf crew, but it just looks like shit\u003cbr\u003eevery time lol\u003cbr\u003e2. That’s strange. Maybe the model struggles when you\u003cbr\u003ehave multiple figures on one base image? Might\u003cbr\u003ehave to convert them individually?","\u003cb\u003eKeyword:\u003c\u002fb\u003e quality degradation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Support says there is no problem but quality is\u003cbr\u003e10x worst than before and even the playground has\u003cbr\u003eissues\u003cbr\u003e2. This is something they do regularly that only\u003cbr\u003epower users will notice. They launch a model at\u003cbr\u003efull power to allow the hype train to give them\u003cbr\u003efree advertising, then once they've gotten the\u003cbr\u003eexposure they want, they optimize it which\u003cbr\u003edrastically lowers quality. I noticed this","\u003cb\u003eKeyword:\u003c\u002fb\u003e object accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I'm not trying to be mean, but It's a freaking\u003cbr\u003eblack triangle with three lights at each corner.\u003cbr\u003eWhat service were u using that couldn't get this\u003cbr\u003eone, right? lol\u003cbr\u003e2. No center light?","\u003cb\u003eKeyword:\u003c\u002fb\u003e representation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I asked 'why drawing a female doctor?' The answer\u003cbr\u003ewas\u003cbr\u003e2. Then I followed with the question 'If you were\u003cbr\u003emindful of female representation, how about\u003cbr\u003erepresentation of 'colored' doctors as obviously\u003cbr\u003eyour default pic was 'white doctor'? … and the\u003cbr\u003eanswer was :","\u003cb\u003eKeyword:\u003c\u002fb\u003e impossible object\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. my favorite image generator, midjourney, can't get\u003cbr\u003ea penrose triangle correct [left] but if you feed\u003cbr\u003eit the stock image and ask it to retexture, then\u003cbr\u003eit tends to do well with the geometry of the\u003cbr\u003ediagram [right]\u003cbr\u003e2. i think there's a lot we (or at least i) don't\u003cbr\u003eunderstand about how image models handle local\u003cbr\u003eversus global geometry. midjourney is clearly\u003cbr\u003egetting a lot of the segmentation correct, and yet\u003cbr\u003eit cannot generate a penrose triangle on its own\u003cbr\u003e(yet)...","\u003cb\u003eKeyword:\u003c\u002fb\u003e aesthetic\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. An original design, no doubt, but I’m not sure\u003cbr\u003ebrands would sell much with such a demonic\u003cbr\u003eaesthetic\u003cbr\u003e2. Looks like a 80s ad that was designed in 2025, by\u003cbr\u003ea program.  Zero 80s aesthetic here.","\u003cb\u003eKeyword:\u003c\u002fb\u003e badges\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Look at the badges!\u003cbr\u003e2. Proof: “Thought for 7 seconds”","\u003cb\u003eKeyword:\u003c\u002fb\u003e feature naming\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Hah, even GPT-4o doesn't know the right name for\u003cbr\u003eits own feature!\u003cbr\u003e2. I pressed it asking what it's called, and it said\u003cbr\u003ethat gpt4-o is multimodal and has the image\u003cbr\u003egeneration natively.  Only asking for the image\u003cbr\u003ewas I able to get it to name itself.","\u003cb\u003eKeyword:\u003c\u002fb\u003e eyes\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Maybe I'm biassed, but for me, these generated\u003cbr\u003ethumbnails are always missing something. It's\u003cbr\u003eeyes. They look soulless (of course!)\u003cbr\u003e2. It’s a game changer but it’s always screwing with\u003cbr\u003ethe eyes","\u003cb\u003eKeyword:\u003c\u002fb\u003e normalcy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. why is she still so scary\u003cbr\u003e2. we will know we’ve hit ASI if it can then make her\u003cbr\u003eless crazy","\u003cb\u003eKeyword:\u003c\u002fb\u003e wireframe accuracy\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. this is not gatekeeping this is just stating a\u003cbr\u003efact. the wireframe turns into monster truck\u003cbr\u003edrawings lol this is not a high quality accurate\u003cbr\u003edepiction of a wireframe. you are not correct and\u003cbr\u003eany 3D artist will tell you this.\u003cbr\u003e2. yes it would be a texture in most cases. If it was\u003cbr\u003emodeled it would not be a line drawing as it is\u003cbr\u003ehere. there is also a cylinder, a basic 3D\u003cbr\u003eprimitive that isn't modeled well. at the end of\u003cbr\u003ethe day though it's a 2D image of a wireframe and\u003cbr\u003eit doesnt really mean anything.","\u003cb\u003eKeyword:\u003c\u002fb\u003e imperfection\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. it's got a small imperfection on its right hand\u003cbr\u003ebut I'm only trying to show first prompts and not\u003cbr\u003efinished products -- this is insane\u003cbr\u003e2. Pre launch imperfect snoozies. Priceless","\u003cb\u003eKeyword:\u003c\u002fb\u003e rind\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Done in Copilot. Seems to not include the rind.\u003cbr\u003e2. Thank you very much. Thank you for your prompt. I\u003cbr\u003ewas hoping my peacock would have the seeds just\u003cbr\u003elike that. They just added in more things you can\u003cbr\u003edo in Copilot. Anime style is one I tried. I might\u003cbr\u003erevisit this prompt and see if I can get some\u003cbr\u003erind. Here is the anime style.","\u003cb\u003eKeyword:\u003c\u002fb\u003e prompt details\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I didn't get exactly what the prompt wanted but I\u003cbr\u003ethought they turned out pretty cute so I thought\u003cbr\u003eI'd share\u003cbr\u003e2. The first one is more in line with the prompt, but\u003cbr\u003ethey are all so cute!","\u003cb\u003eKeyword:\u003c\u002fb\u003e text details\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It seems like it adds one string of text correctly\u003cbr\u003e(like the counter strike screenshot) and the rest\u003cbr\u003eis wrong. For instance in the fallout one the map\u003cbr\u003egoes from South, to South West, to North without\u003cbr\u003eWest-West.\u003cbr\u003e2. I mean technically it changes some of the text.\u003cbr\u003ePeople will have to build a tool that can change\u003cbr\u003esmall details easily for this to work for\u003cbr\u003edesigners.","\u003cb\u003eKeyword:\u003c\u002fb\u003e sliced styles\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. It has more trouble understanding as you increase\u003cbr\u003ethe number of slices...\u003cbr\u003e2. It can't seem to understand the idea beyond\u003cbr\u003ethat...","\u003cb\u003eKeyword:\u003c\u002fb\u003e memory bleed\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. As I feared, 4o is errantly using images from old\u003cbr\u003echats as references for new image requests in new\u003cbr\u003echats now. This memory is anything but intelligent\u003cbr\u003e(for image generation)\u003cbr\u003e2. Absolutely worse, and also has the potential of\u003cbr\u003epoisoning further chats if it previously started\u003cbr\u003ehallucinating.","\u003cb\u003eKeyword:\u003c\u002fb\u003e missing object\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. heh yeah the one eyed snake is still hidden in\u003cbr\u003emost pictures\u003c3\u003cbr\u003e2. I'd definitely buy one! But where is the bicycle?","\u003cb\u003eKeyword:\u003c\u002fb\u003e mockup usability\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. I’ll be doing a-lot of this in the coming months.\u003cbr\u003eNow just need Ai to be good at placing logos and\u003cbr\u003edesigns on mockups and this would be a game\u003cbr\u003echanger.\u003cbr\u003e2. Good platform but please make a secondary way\u003cbr\u003eapart from connection nodes. Many professional\u003cbr\u003ecreatives ran away from 3d suites because of this\u003cbr\u003ecomplex pipeline style. Image drag and drop would\u003cbr\u003ebe cool, also zoom is crazy hard to control when\u003cbr\u003ejust wanting a simple output","\u003cb\u003eKeyword:\u003c\u002fb\u003e translation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. First, here's the output with gemini:\u003cbr\u003eOriginal\u002f'translated' Quite bad.\u003cbr\u003e2. Here's grok Original\u002f'translated' Quite\u003cbr\u003ehallucinated!","\u003cb\u003eKeyword:\u003c\u002fb\u003e cartoonish\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Yeah it’s annoying because they actually look\u003cbr\u003edecent when I run it on the ChatGPT app but as\u003cbr\u003esoon as I go to the API, even on high quality, I\u003cbr\u003eget cartoons.\u003cbr\u003e2. I've been wondering the same thing! Can't get\u003cbr\u003eimages to look real real.","\u003cb\u003eKeyword:\u003c\u002fb\u003e overinterpretation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Yeah, I will say one of my complaints about Grok\u003cbr\u003eis that it tries to be smarter by using previous\u003cbr\u003einformation and “reading between the lines” when\u003cbr\u003eyou’re literally just trying to tell it to do\u003cbr\u003esomething and there’s nothing deeper behind it.\u003cbr\u003e2. exactly. it does too much lol. it almost always\u003cbr\u003etakes creative liberties when generating photos, &\u003cbr\u003ethat’s often not useful.","\u003cb\u003eKeyword:\u003c\u002fb\u003e facial coherence\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Here is a sample response. My face was recreated,\u003cbr\u003eand it is unable to preserve my facial details.\u003cbr\u003e2. The uncanny valley hits different in AI generated\u003cbr\u003econtent. Still better than most NFT pfps tho","\u003cb\u003eKeyword:\u003c\u002fb\u003e context-limitation\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. Did a talk\u002fediting article on this. It only works\u003cbr\u003ein contexts with a rich range of 1: aesthetics\u003cbr\u003e(with their own political\u002fhistorical\u003cbr\u003eentanglements) 2: symbolism. Otherwise it's cringe\u003cbr\u003e(pic rel).\u003cbr\u003e2. Yeah for quick memes it’s too slow","\u003cb\u003eKeyword:\u003c\u002fb\u003e color\u003cbr\u003e\u003cb\u003eCount:\u003c\u002fb\u003e 2\u003cbr\u003e\u003cbr\u003e\u003cb\u003eSamples:\u003c\u002fb\u003e\u003cbr\u003e1. would you tell it to remove the yellow\u003cbr\u003e2. They need to figure out the wam hue thing. Would\u003cbr\u003ebe so much more powerful if every image didn’t\u003cbr\u003elook like it had an orange filter on. This model’s\u003cbr\u003eweakness is truly expressive color. Cc @sama"],"hoverlabel":{"align":"left","bgcolor":"white","bordercolor":"lightgray","font":{"size":11}},"mode":"text","showlegend":false,"text":["identity","details","style","text rendering","consistency","coherence","identity mismatch","aspect ratio","reasoning","accuracy","quality","style fidelity","realism","style mismatch","proportions","color tint","fidelity","text accuracy","color fidelity","dimensions","text","hands","transparency","faces","color balance","anatomy","object coherence","design quality","location accuracy","resolution","color tone","hallucination","design accuracy","color shift","facial expression","blending","detail fidelity","coherency","color contrast","ghibli style","counting","detail","annotation","style rigidity","access","text errors","3D realism","prompt comprehension","inspiration","layout preservation","weaponization","self-awareness","missing details","color accuracy","text quality","muscle growth","sharpness","refinement","color bias","detail differentiation","latency","authenticity","foam, structure","yellow tint","inconsistencies","reflection","logos and visuals","ingredient accuracy","labeling","style bias","height manipulation","symbolism","regression","contrast","style,concept","story fidelity","product placement","style switching","multi-subject","quality degradation","object accuracy","representation","impossible object","aesthetic","badges","feature naming","eyes","normalcy","wireframe accuracy","imperfection","rind","prompt details","text details","sliced styles","memory bleed","missing object","mockup usability","translation","cartoonish","overinterpretation","facial coherence","context-limitation","color"],"textfont":{"color":["rgb(33, 166, 133)","rgb(63, 72, 137)","rgb(31, 159, 136)","rgb(30, 155, 138)","rgb(55, 90, 140)","rgb(66, 190, 113)","rgb(63, 72, 137)","rgb(72, 33, 115)","rgb(35, 169, 131)","rgb(31, 153, 138)","rgb(72, 29, 111)","rgb(38, 173, 129)","rgb(66, 65, 134)","rgb(105, 205, 91)","rgb(61, 77, 138)","rgb(37, 133, 142)","rgb(45, 113, 142)","rgb(68, 191, 112)","rgb(36, 170, 131)","rgb(69, 56, 130)","rgb(61, 188, 116)","rgb(62, 76, 138)","rgb(42, 120, 142)","rgb(218, 227, 25)","rgb(63, 71, 136)","rgb(200, 224, 32)","rgb(70, 48, 126)","rgb(57, 85, 140)","rgb(46, 111, 142)","rgb(32, 146, 140)","rgb(162, 218, 55)","rgb(117, 208, 84)","rgb(44, 115, 142)","rgb(59, 82, 139)","rgb(59, 187, 117)","rgb(94, 201, 98)","rgb(72, 40, 120)","rgb(68, 1, 84)","rgb(57, 85, 140)","rgb(32, 146, 140)","rgb(53, 95, 141)","rgb(69, 53, 129)","rgb(226, 228, 24)","rgb(34, 168, 132)","rgb(208, 225, 28)","rgb(60, 79, 138)","rgb(221, 227, 24)","rgb(132, 212, 75)","rgb(71, 45, 123)","rgb(68, 57, 131)","rgb(39, 126, 142)","rgb(74, 193, 109)","rgb(47, 180, 124)","rgb(37, 132, 142)","rgb(48, 105, 142)","rgb(33, 165, 133)","rgb(62, 76, 138)","rgb(72, 27, 109)","rgb(63, 71, 136)","rgb(31, 162, 135)","rgb(127, 211, 78)","rgb(50, 182, 122)","rgb(35, 136, 142)","rgb(72, 23, 105)","rgb(59, 81, 139)","rgb(70, 48, 126)","rgb(59, 81, 139)","rgb(127, 211, 78)","rgb(71, 19, 101)","rgb(236, 229, 27)","rgb(68, 57, 131)","rgb(165, 219, 54)","rgb(44, 115, 142)","rgb(208, 225, 28)","rgb(39, 126, 142)","rgb(31, 158, 137)","rgb(66, 64, 134)","rgb(32, 163, 134)","rgb(72, 22, 104)","rgb(202, 225, 31)","rgb(229, 228, 25)","rgb(72, 26, 108)","rgb(41, 121, 142)","rgb(59, 81, 139)","rgb(72, 29, 111)","rgb(31, 149, 139)","rgb(55, 184, 120)","rgb(42, 119, 142)","rgb(36, 134, 142)","rgb(69, 4, 87)","rgb(72, 27, 109)","rgb(71, 46, 124)","rgb(176, 221, 47)","rgb(38, 130, 142)","rgb(37, 171, 130)","rgb(31, 151, 139)","rgb(53, 95, 141)","rgb(57, 85, 140)","rgb(30, 157, 137)","rgb(64, 70, 136)","rgb(32, 146, 140)","rgb(72, 33, 115)","rgb(71, 17, 100)"],"family":"sans-serif","size":[64,54,53,35,32,32,18,17,15,15,14,14,14,13,13,13,13,12,12,12,12,12,12,12,11,11,11,11,8,8,8,8,7,7,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]},"x":[181.5,161.5,122.5,175.0,176.5,182.5,168.0,282.0,271.5,85.0,22.0,241.0,168.5,186.5,285.5,139.0,245.5,232.0,206.5,246.0,331.5,312.0,171.0,230.0,146.0,175.5,155.0,56.5,246.0,81.0,159.0,304.5,118.5,9.5,132.0,23.5,57.0,153.5,66.0,314.0,121.0,311.0,333.0,92.0,212.0,92.5,30.0,236.0,33.0,152.5,324.0,52.0,238.5,243.0,251.0,312.5,60.5,217.5,55.0,235.0,60.5,118.5,62.5,164.0,62.0,121.5,128.5,165.5,299.0,144.5,38.5,75.0,25.5,66.0,217.5,284.5,240.5,249.5,28.5,191.0,103.5,187.0,239.5,204.5,136.0,136.0,142.0,130.0,111.5,273.5,207.0,112.0,207.5,306.5,125.5,293.5,193.5,305.5,82.5,337.5,308.5,179.5,314.5],"y":[199.0,259.0,151.5,101.5,58.0,305.0,41.0,156.5,130.0,77.0,194.5,83.0,22.5,328.5,261.0,284.0,173.5,287.5,319.0,141.5,148.0,246.5,129.5,24.5,230.0,8.5,118.5,129.5,73.5,291.0,341.0,117.0,32.0,180.0,222.5,148.5,88.5,87.5,116.0,239.0,20.0,232.5,174.5,306.0,273.0,178.5,158.5,166.0,253.5,81.0,139.0,220.5,121.0,32.0,282.0,224.0,290.0,204.0,69.5,235.5,178.0,317.5,172.5,274.5,235.5,102.5,170.5,185.0,277.5,273.0,252.0,230.5,238.5,204.5,226.5,163.0,221.5,275.5,142.5,33.5,275.5,177.5,115.5,19.0,13.5,75.5,241.0,195.5,89.5,265.5,263.5,325.5,339.5,260.5,177.5,194.0,172.5,267.5,71.5,201.0,255.5,270.0,214.5],"type":"scatter","hoverinfo":"none"}],"layout":{"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"visible":false,"range":[0,350]},"yaxis":{"visible":false,"range":[0,350],"scaleanchor":"x"},"margin":{"l":0,"r":0,"t":0,"b":0},"plot_bgcolor":"white","width":350,"height":350,"hovermode":"closest","hoverdistance":20}};
            var wordData = [{"x": 181.5, "y": 199.0, "text": "identity", "font_size": 64, "color": "rgb(33, 166, 133)", "hover_html": "<b>Keyword:</b> identity<br><b>Count:</b> 36<br><br><b>Samples:</b><br>1. Looks like GPT 4o make you put on a few pounds<br>2. Typed this same prompt but chatgpt isn't giving<br>the same result...... chatgpt is completely<br>changing my face<br>3. Oh damn, it improved this thumbnail significantly.<br>Too bad that guy doesn't look like me but it might<br>be good enough!", "raw_count": 36, "samples": ["Looks like GPT 4o make you put on a few pounds", "Typed this same prompt but chatgpt isn't giving the same result...... chatgpt is completely changing my face", "Oh damn, it improved this thumbnail significantly. Too bad that guy doesn't look like me but it might be good enough!"]}, {"x": 161.5, "y": 259.0, "text": "details", "font_size": 54, "color": "rgb(63, 72, 137)", "hover_html": "<b>Keyword:</b> details<br><b>Count:</b> 25<br><br><b>Samples:</b><br>1. Precision: OpenAI follows edits better. Gemini<br>misses details.<br>2. Context Awareness: OpenAI adjusts more than<br>asked\u2014e.g., adding a gun also made the character\u2019s<br>face more serious. Smart or intrusive?<br>3. It still changes too much details from the<br>original object", "raw_count": 25, "samples": ["Precision: OpenAI follows edits better. Gemini misses details.", "Context Awareness: OpenAI adjusts more than asked\u2014e.g., adding a gun also made the character\u2019s face more serious. Smart or intrusive?", "It still changes too much details from the original object"]}, {"x": 122.5, "y": 151.5, "text": "style", "font_size": 53, "color": "rgb(31, 159, 136)", "hover_html": "<b>Keyword:</b> style<br><b>Count:</b> 24<br><br><b>Samples:</b><br>1. yeah, it looked terrible<br>2. Is it just me or does the art look like candy ?<br>3. haha yea & a bit of claymation", "raw_count": 24, "samples": ["yeah, it looked terrible", "Is it just me or does the art look like candy ?", "haha yea & a bit of claymation"]}, {"x": 175.0, "y": 101.5, "text": "text rendering", "font_size": 35, "color": "rgb(30, 155, 138)", "hover_html": "<b>Keyword:</b> text rendering<br><b>Count:</b> 20<br><br><b>Samples:</b><br>1. You're not alone. Loved it at first but now the<br>results are average at best<br>2. low is pretty good if you want to generate some<br>simple illustrations but bad at handling text<br>3. yep, it's pretty bad at handling text unless you<br>want it to generate just a word or two", "raw_count": 20, "samples": ["You're not alone. Loved it at first but now the results are average at best", "low is pretty good if you want to generate some simple illustrations but bad at handling text", "yep, it's pretty bad at handling text unless you want it to generate just a word or two"]}, {"x": 176.5, "y": 58.0, "text": "consistency", "font_size": 32, "color": "rgb(55, 90, 140)", "hover_html": "<b>Keyword:</b> consistency<br><b>Count:</b> 17<br><br><b>Samples:</b><br>1. This is really useful Dan, thank you, also do you<br>have some tips on image editing with 4o, like when<br>I generate image with it, and I want it to make<br>changes in it, it changes alot more than what I<br>ask even though I explicitly tell it not to change<br>anything else.<br>2. looks like sd1.5 though<br>3. Yeah, it changed an awful lot in this 'edit'. Kind<br>of interesting to see just how much is different;<br>changed the sign, the background people, etc.", "raw_count": 17, "samples": ["This is really useful Dan, thank you, also do you have some tips on image editing with 4o, like when I generate image with it, and I want it to make changes in it, it changes alot more than what I ask even though I explicitly tell it not to change anything else.", "looks like sd1.5 though", "Yeah, it changed an awful lot in this 'edit'. Kind of interesting to see just how much is different; changed the sign, the background people, etc."]}, {"x": 182.5, "y": 305.0, "text": "coherence", "font_size": 32, "color": "rgb(66, 190, 113)", "hover_html": "<b>Keyword:</b> coherence<br><b>Count:</b> 17<br><br><b>Samples:</b><br>1. The last panel makes no sense.<br>2. This one was intriguing. It executes the image<br>text as a prompt and executed it. It even added<br>the @OpenAI logo, that was not in the original,<br>and switched position of the prompt for logical<br>coherence, probably by following the context of<br>previous imagens.<br>3. In both replies it thinks I'll live a long life..<br>Both images are flawed though.", "raw_count": 17, "samples": ["The last panel makes no sense.", "This one was intriguing. It executes the image text as a prompt and executed it. It even added the @OpenAI logo, that was not in the original, and switched position of the prompt for logical coherence, probably by following the context of previous imagens.", "In both replies it thinks I'll live a long life.. Both images are flawed though."]}, {"x": 168.0, "y": 41.0, "text": "identity mismatch", "font_size": 18, "color": "rgb(63, 72, 137)", "hover_html": "<b>Keyword:</b> identity mismatch<br><b>Count:</b> 13<br><br><b>Samples:</b><br>1. I don\u2019t know what it is with me personally. But I<br>cannot to get gpt to make the outputs look like<br>me. It adds at least 10-15 years..<br>2. it gave me a hybrid of myself and that dude<br>3. same  using 4o  close but not 100% there<br>prompting it to retry a few more times", "raw_count": 13, "samples": ["I don\u2019t know what it is with me personally. But I cannot to get gpt to make the outputs look like me. It adds at least 10-15 years..", "it gave me a hybrid of myself and that dude", "same\n\nusing 4o\n\nclose but not 100% there\n\nprompting it to retry a few more times"]}, {"x": 282.0, "y": 156.5, "text": "aspect ratio", "font_size": 17, "color": "rgb(72, 33, 115)", "hover_html": "<b>Keyword:</b> aspect ratio<br><b>Count:</b> 11<br><br><b>Samples:</b><br>1. The issue here, while minor, was that it keeps<br>getting 1:1 results, and when I ask for 16:9 ar,<br>it changes it slightly, stretching the shot a bit.<br>2. Only limitation is you can't really get the exact<br>aspect ratio for YouTube thumbnails (1080x1920)<br>bcs the width is smaller<br>3. Note: GPT 4o, as great as it is DOES NOT produce<br>images at 16:9 so I basically had to use<br>Generative Fill in Photoshop to manually expand<br>each image. Not a biggie, but surely just provide<br>those aspect ratios @OpenAI", "raw_count": 11, "samples": ["The issue here, while minor, was that it keeps getting 1:1 results, and when I ask for 16:9 ar, it changes it slightly, stretching the shot a bit.", "Only limitation is you can't really get the exact aspect ratio for YouTube thumbnails (1080x1920) bcs the width is smaller", "Note: GPT 4o, as great as it is DOES NOT produce images at 16:9 so I basically had to use Generative Fill in Photoshop to manually expand each image. Not a biggie, but surely just provide those aspect ratios @OpenAI"]}, {"x": 271.5, "y": 130.0, "text": "reasoning", "font_size": 15, "color": "rgb(35, 169, 131)", "hover_html": "<b>Keyword:</b> reasoning<br><b>Count:</b> 8<br><br><b>Samples:</b><br>1. A lot of these don't make it out of reasoning<br>space for me, either!<br>2. Sorry, this is fake news. Gave it the exact prompt<br>in your screenshot, they pre-process the prompt.<br>3. it seems \u201clazy\u201d \u2014 will just not think or search<br>and make up an answer right away for some prompts", "raw_count": 8, "samples": ["A lot of these don't make it out of reasoning space for me, either!", "Sorry, this is fake news. Gave it the exact prompt in your screenshot, they pre-process the prompt.", "it seems \u201clazy\u201d \u2014 will just not think or search and make up an answer right away for some prompts"]}, {"x": 85.0, "y": 77.0, "text": "accuracy", "font_size": 15, "color": "rgb(31, 153, 138)", "hover_html": "<b>Keyword:</b> accuracy<br><b>Count:</b> 8<br><br><b>Samples:</b><br>1. pretty much all the small details are slightly<br>changed. 4o is great for visual \u201cparaphrasing\u201d but<br>it doesn\u2019t preserve anything on a pixel level<br>2. It\u2019s a cool result but not quite accurate - more<br>of using source material as a reference instead of<br>a copy<br>3. minus the face of the person, who is totally<br>different.", "raw_count": 8, "samples": ["pretty much all the small details are slightly changed. 4o is great for visual \u201cparaphrasing\u201d but it doesn\u2019t preserve anything on a pixel level", "It\u2019s a cool result but not quite accurate - more of using source material as a reference instead of a copy", "minus the face of the person, who is totally different."]}, {"x": 22.0, "y": 194.5, "text": "quality", "font_size": 14, "color": "rgb(72, 29, 111)", "hover_html": "<b>Keyword:</b> quality<br><b>Count:</b> 7<br><br><b>Samples:</b><br>1. It still has some ways to go tbh, but it\u2019s<br>trending towards fixing whatever generating<br>mistakes it makes.  Canva is still a lot better<br>quality wise, but the fact that chatgpt can just<br>remove \u201cwriter\u2019s block\u201d (or graphic artist\u2019s<br>block?) is what\u2019ll take it to the top.<br>2. This, exactly.  It was fantastic during its<br>initial rollout, but now it\u2019s frustrating, boring,<br>and disappointing. I\u2019ve lost interest because I<br>assume everything will be rejected or inaccurate.<br>Please improve  at non-Ghibli images. It\u2019s lost<br>its luster.<br>3. Yes please! quality dropped significantly!", "raw_count": 7, "samples": ["It still has some ways to go tbh, but it\u2019s trending towards fixing whatever generating mistakes it makes.\n\nCanva is still a lot better quality wise, but the fact that chatgpt can just remove \u201cwriter\u2019s block\u201d (or graphic artist\u2019s block?) is what\u2019ll take it to the top.", "This, exactly.\n\nIt was fantastic during its initial rollout, but now it\u2019s frustrating, boring, and disappointing. I\u2019ve lost interest because I assume everything will be rejected or inaccurate. Please improve  at non-Ghibli images. It\u2019s lost its luster.", "Yes please! quality dropped significantly!"]}, {"x": 241.0, "y": 83.0, "text": "style fidelity", "font_size": 14, "color": "rgb(38, 173, 129)", "hover_html": "<b>Keyword:</b> style fidelity<br><b>Count:</b> 7<br><br><b>Samples:</b><br>1. Close Up portraits looking good on MJ V7, ChatGPT<br>4o Imagegen doesn't even come close.<br>2. That seems like a DALLE-3 output? I put the prompt<br>into Sora with the code and this is the output I<br>got from 4o image gen<br>3. Instead of Digital art please use realistic image<br>itself", "raw_count": 7, "samples": ["Close Up portraits looking good on MJ V7, ChatGPT 4o Imagegen doesn't even come close.", "That seems like a DALLE-3 output? I put the prompt into Sora with the code and this is the output I got from 4o image gen", "Instead of Digital art please use realistic image itself"]}, {"x": 168.5, "y": 22.5, "text": "realism", "font_size": 14, "color": "rgb(66, 65, 134)", "hover_html": "<b>Keyword:</b> realism<br><b>Count:</b> 7<br><br><b>Samples:</b><br>1. Midjourney can look more real than that<br>2. It\u2019s pretty cool, I tried it as well but it\u2019s not<br>accurate yet and lack of realism. Pushed it<br>further with the prompts to get more realism and<br>accuracy but still no good, at least not for<br>client work\u2026 But for fun or even an ad with a<br>purpose in this format, it could be cool.<br>3. Agree! I haven\u2019t tried any of the upscalers to<br>make it more realistic yet, but it looks very<br>promising", "raw_count": 7, "samples": ["Midjourney can look more real than that", "It\u2019s pretty cool, I tried it as well but it\u2019s not accurate yet and lack of realism. Pushed it further with the prompts to get more realism and accuracy but still no good, at least not for client work\u2026 But for fun or even an ad with a purpose in this format, it could be cool.", "Agree! I haven\u2019t tried any of the upscalers to make it more realistic yet, but it looks very promising"]}, {"x": 186.5, "y": 328.5, "text": "style mismatch", "font_size": 13, "color": "rgb(105, 205, 91)", "hover_html": "<b>Keyword:</b> style mismatch<br><b>Count:</b> 6<br><br><b>Samples:</b><br>1. Not accurate, but I think his particular style<br>might be more suited to diffusion anyway (this is<br>4o)<br>2. I have to rework the prompt.  Copilot gave me fun<br>images but they are not like your images at all.<br>3. This was almost perfect.   Maybe the wrong model?<br>I used Kling here.", "raw_count": 6, "samples": ["Not accurate, but I think his particular style might be more suited to diffusion anyway (this is 4o)", "I have to rework the prompt.  Copilot gave me fun images but they are not like your images at all.", "This was almost perfect. \n\nMaybe the wrong model?  I used Kling here."]}, {"x": 285.5, "y": 261.0, "text": "proportions", "font_size": 13, "color": "rgb(61, 77, 138)", "hover_html": "<b>Keyword:</b> proportions<br><b>Count:</b> 6<br><br><b>Samples:</b><br>1. Why are they so big lol<br>2. Proportions are a little off, but still cool<br>3. I love the abomination of a shirt it created. I<br>want it. It was also pretty generous with my arms.<br>Haha", "raw_count": 6, "samples": ["Why are they so big lol", "Proportions are a little off, but still cool", "I love the abomination of a shirt it created. I want it. It was also pretty generous with my arms. Haha"]}, {"x": 139.0, "y": 284.0, "text": "color tint", "font_size": 13, "color": "rgb(37, 133, 142)", "hover_html": "<b>Keyword:</b> color tint<br><b>Count:</b> 6<br><br><b>Samples:</b><br>1. I'm surprised I haven't yet seen anybody mention<br>what is most likely the real answer: Native GPT-4o<br>image generation. GPT-4o is one of the newest,<br>most advanced AI image generators with the best<br>understanding \u2013 but has a weird tendency to make<br>everything really sepia by default.<br>2. Yeah, it\u2019s otherwise really good, I\u2019m hoping they<br>fix this\u2026<br>3. the 4o image generator has an orange tint because<br>that's a way openai chose to watermark these<br>generated images i guess", "raw_count": 6, "samples": ["I'm surprised I haven't yet seen anybody mention what is most likely the real answer: Native GPT-4o image generation. GPT-4o is one of the newest, most advanced AI image generators with the best understanding \u2013 but has a weird tendency to make everything really sepia by default.", "Yeah, it\u2019s otherwise really good, I\u2019m hoping they fix this\u2026", "the 4o image generator has an orange tint because that's a way openai chose to watermark these generated images i guess"]}, {"x": 245.5, "y": 173.5, "text": "fidelity", "font_size": 13, "color": "rgb(45, 113, 142)", "hover_html": "<b>Keyword:</b> fidelity<br><b>Count:</b> 6<br><br><b>Samples:</b><br>1. I noticed that my product being generated by AI is<br>never identical enough to really test. How do you<br>tackle that issue?<br>2. Than AI aint working. Maybe it\u2019s cheaper to let a<br>designer perfect it<br>3. fortnite one is a bit of a stretch hah", "raw_count": 6, "samples": ["I noticed that my product being generated by AI is never identical enough to really test. How do you tackle that issue?", "Than AI aint working. Maybe it\u2019s cheaper to let a designer perfect it", "fortnite one is a bit of a stretch hah"]}, {"x": 232.0, "y": 287.5, "text": "text accuracy", "font_size": 12, "color": "rgb(68, 191, 112)", "hover_html": "<b>Keyword:</b> text accuracy<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. Text accuracy on generated images is a hit and<br>miss though<br>2. Pretty cool. It thought to add a logo but that 4th<br>letter of cloud was not going to be a 'u' lol<br>3. Bottom left on the can if you read the words and<br>same with the bottom right. A few weeks ago it was<br>bang on. Word for word, crisp text, no touch up<br>required. Now depending on the object and writing<br>it can get pretty wonky.", "raw_count": 5, "samples": ["Text accuracy on generated images is a hit and miss though", "Pretty cool. It thought to add a logo but that 4th letter of cloud was not going to be a 'u' lol", "Bottom left on the can if you read the words and same with the bottom right. A few weeks ago it was bang on. Word for word, crisp text, no touch up required. Now depending on the object and writing it can get pretty wonky."]}, {"x": 206.5, "y": 319.0, "text": "color fidelity", "font_size": 12, "color": "rgb(36, 170, 131)", "hover_html": "<b>Keyword:</b> color fidelity<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. seems good though got the whole style down just a<br>bit more muted<br>2. It is really frustrating :')<br>3. Interesting that Kontext kept the yellowish tint.", "raw_count": 5, "samples": ["seems good though got the whole style down just a bit more muted", "It is really frustrating :')", "Interesting that Kontext kept the yellowish tint."]}, {"x": 246.0, "y": 141.5, "text": "dimensions", "font_size": 12, "color": "rgb(69, 56, 130)", "hover_html": "<b>Keyword:</b> dimensions<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. Hey @CoderInTown, it seems you want a wide image<br>from Grok like Gemini's! Grok's fixed at 1024x768<br>(4:3), so no custom sizes, but you can get a<br>\"looooong\" feel with a prompt like: \"A black and<br>purple Bugatti in front of the Burj Khalifa, wide-<br>angle view, with Dubai\u2019s skyline\"<br>2. Getting specific dimensions can be a little<br>tricky. I usually take the output from GPT-4o and<br>refine the dimensions in Figma or Canva.<br>3. Does it get the dimensions right? That's the only<br>thing I could see being an issue with using it for<br>interior design. Like it has to know the<br>dimensions of the room and the dimensions of the<br>objects no?", "raw_count": 5, "samples": ["Hey @CoderInTown, it seems you want a wide image from Grok like Gemini's! Grok's fixed at 1024x768 (4:3), so no custom sizes, but you can get a \"looooong\" feel with a prompt like: \"A black and purple Bugatti in front of the Burj Khalifa, wide-angle view, with Dubai\u2019s skyline\"", "Getting specific dimensions can be a little tricky. I usually take the output from GPT-4o and refine the dimensions in Figma or Canva.", "Does it get the dimensions right? That's the only thing I could see being an issue with using it for interior design. Like it has to know the dimensions of the room and the dimensions of the objects no?"]}, {"x": 331.5, "y": 148.0, "text": "text", "font_size": 12, "color": "rgb(61, 188, 116)", "hover_html": "<b>Keyword:</b> text<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. Obviously not perfect on the text\u2026 but still\u2026<br>straight \u2018code-to-visual\u2019 bypassing the need for<br>an interpreter! It\u2019s grasping some deep internal<br>sub-strata that allows it to intuitively and non<br>mechanically translate between different surface<br>level representations.<br>2. I\u2019d rate your AI-generated image 7/10. The<br>character\u2019s design and cozy indoor vibe capture<br>Studio Ghibli\u2019s essence well, but the text \u201c- my<br>day \u201d deviates from their usual aesthetic. AI<br>tools like GPT-4o are great for this style,<br>though!<br>3. A couple of text mess-ups but much better than<br>most image generators.", "raw_count": 5, "samples": ["Obviously not perfect on the text\u2026 but still\u2026 straight \u2018code-to-visual\u2019 bypassing the need for an interpreter! It\u2019s grasping some deep internal sub-strata that allows it to intuitively and non mechanically translate between different surface level representations.", "I\u2019d rate your AI-generated image 7/10. The character\u2019s design and cozy indoor vibe capture Studio Ghibli\u2019s essence well, but the text \u201c- my day \u201d deviates from their usual aesthetic. AI tools like GPT-4o are great for this style, though!", "A couple of text mess-ups but much better than most image generators."]}, {"x": 312.0, "y": 246.5, "text": "hands", "font_size": 12, "color": "rgb(62, 76, 138)", "hover_html": "<b>Keyword:</b> hands<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. those hands<br>2. She can turn her hand using #openai<br>3. Nice haha. Still has trouble with hands I see.", "raw_count": 5, "samples": ["those hands", "She can turn her hand using #openai", "Nice haha. Still has trouble with hands I see."]}, {"x": 171.0, "y": 129.5, "text": "transparency", "font_size": 12, "color": "rgb(42, 120, 142)", "hover_html": "<b>Keyword:</b> transparency<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. Heh .. well .. maybe it glued the ponytail to the<br>helmet. But there seems some hair is sticking out<br>from between the helmet and the suit. I guess that<br>can even happen in real live when you put on a<br>helmet.<br>2. If you look at the front part, you\u2019ll see the see<br>through part of the helmet is messed up anyway.<br>It\u2019s not quite clear there\u2019s an actual closed<br>helmet here.<br>3. I didn't really notice that, as transparancy can<br>be odd. Like sometimes you can see it and<br>sometimes not. But yeahr the left side seems to<br>have a small piece of transparant material. And<br>then nothing, even a bit of hair seems to stick<br>out of the helmet.", "raw_count": 5, "samples": ["Heh .. well .. maybe it glued the ponytail to the helmet. But there seems some hair is sticking out from between the helmet and the suit. I guess that can even happen in real live when you put on a helmet.", "If you look at the front part, you\u2019ll see the see through part of the helmet is messed up anyway. It\u2019s not quite clear there\u2019s an actual closed helmet here.", "I didn't really notice that, as transparancy can be odd. Like sometimes you can see it and sometimes not. But yeahr the left side seems to have a small piece of transparant material. And then nothing, even a bit of hair seems to stick out of the helmet."]}, {"x": 230.0, "y": 24.5, "text": "faces", "font_size": 12, "color": "rgb(218, 227, 25)", "hover_html": "<b>Keyword:</b> faces<br><b>Count:</b> 5<br><br><b>Samples:</b><br>1. It\u2019s close, but it still makes some minor changes<br>to the faces. The clothes don\u2019t matter so much.<br>The faces are important imo.<br>2. That's what I noticed too. Too much improvement<br>sometimes leeds to overdrawn mimic in gpt4o.<br>3. I've picked up some ideas from online and the<br>comments here that I can maybe prompt ChatGPT to<br>not adjust the image aspect ratio, body and face<br>features too much. I'll try this next time.", "raw_count": 5, "samples": ["It\u2019s close, but it still makes some minor changes to the faces. The clothes don\u2019t matter so much. The faces are important imo.", "That's what I noticed too. Too much improvement sometimes leeds to overdrawn mimic in gpt4o.", "I've picked up some ideas from online and the comments here that I can maybe prompt ChatGPT to not adjust the image aspect ratio, body and face features too much. I'll try this next time."]}, {"x": 146.0, "y": 230.0, "text": "color balance", "font_size": 11, "color": "rgb(63, 71, 136)", "hover_html": "<b>Keyword:</b> color balance<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. great addition. btw, a simple auto white balance<br>post processing could make it even better than<br>chatgpt's.<br>2. Can u make it not yellow ? All 4o images are<br>yellow<br>3. still feels a bit yellow", "raw_count": 4, "samples": ["great addition. btw, a simple auto white balance post processing could make it even better than chatgpt's.", "Can u make it not yellow ? All 4o images are yellow", "still feels a bit yellow"]}, {"x": 175.5, "y": 8.5, "text": "anatomy", "font_size": 11, "color": "rgb(200, 224, 32)", "hover_html": "<b>Keyword:</b> anatomy<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Wild stuff. A pro tip: when asking for camera<br>angles, be super specific with \"35-degree side<br>view from the right\" or similar. These models can<br>struggle with vague spatial prompts, but nail it<br>with precision. Also, watch for subtle anatomy<br>glitches\u2014hands/arms sometimes go rogue.<br>2. Three fingers<br>3. lol maxillary molars don\u2019t come out in one piece.<br>It\u2019s a lie.", "raw_count": 4, "samples": ["Wild stuff. A pro tip: when asking for camera angles, be super specific with \"35-degree side view from the right\" or similar. These models can struggle with vague spatial prompts, but nail it with precision. Also, watch for subtle anatomy glitches\u2014hands/arms sometimes go rogue.", "Three fingers", "lol maxillary molars don\u2019t come out in one piece. It\u2019s a lie."]}, {"x": 155.0, "y": 118.5, "text": "object coherence", "font_size": 11, "color": "rgb(70, 48, 126)", "hover_html": "<b>Keyword:</b> object coherence<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Chatbox doesn't known if it's coming or going.<br>Neither does that car.<br>2. How does it move?!<br>3. It\u2019s good that some of them don\u2019t have random<br>stuff that doesn\u2019t appear to really be anything<br>like AI image generators sometimes do. Except for<br>the \u201cWiFi burger\u201d\u2026", "raw_count": 4, "samples": ["Chatbox doesn't known if it's coming or going. Neither does that car.", "How does it move?!", "It\u2019s good that some of them don\u2019t have random stuff that doesn\u2019t appear to really be anything like AI image generators sometimes do. Except for the \u201cWiFi burger\u201d\u2026"]}, {"x": 56.5, "y": 129.5, "text": "design quality", "font_size": 11, "color": "rgb(57, 85, 140)", "hover_html": "<b>Keyword:</b> design quality<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. They look like shit, stop posting AI slop<br>2. Or get this you could just pay an artist, even a<br>student artist, to create more compelling designs.<br>3. Drake is the only passable one and they all suck", "raw_count": 4, "samples": ["They look like shit, stop posting AI slop", "Or get this you could just pay an artist, even a student artist, to create more compelling designs.", "Drake is the only passable one and they all suck"]}, {"x": 246.0, "y": 73.5, "text": "location accuracy", "font_size": 8, "color": "rgb(46, 111, 142)", "hover_html": "<b>Keyword:</b> location accuracy<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. fyi if you look very carefully it's kinda wrong<br>2. But the locations are wrong in many of the images<br>3. It absolutely cannot be solved with \"better<br>prompting\". That is a blatant lie.", "raw_count": 4, "samples": ["fyi if you look very carefully it's kinda wrong", "But the locations are wrong in many of the images", "It absolutely cannot be solved with \"better prompting\". That is a blatant lie."]}, {"x": 81.0, "y": 291.0, "text": "resolution", "font_size": 8, "color": "rgb(32, 146, 140)", "hover_html": "<b>Keyword:</b> resolution<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Minor addition after some testing. Can increase<br>resolution output of sprite sheet by adding \u201chigh-<br>resolution, cinema4d, 8k render\u201d to 1st prompt.<br>Ends up improving image quality in GIF.<br>2. the biggest thing i hate about 4o is no matter how<br>simple the image if you zoom in u see the noisy<br>pattern that they all have<br>3. That\u2019s true, I usually upscale the images using<br>creative upscaler like clarity or co. to improve<br>that a bit + colors", "raw_count": 4, "samples": ["Minor addition after some testing. Can increase resolution output of sprite sheet by adding \u201chigh-resolution, cinema4d, 8k render\u201d to 1st prompt. Ends up improving image quality in GIF.", "the biggest thing i hate about 4o is no matter how simple the image if you zoom in u see the noisy pattern that they all have", "That\u2019s true, I usually upscale the images using creative upscaler like clarity or co. to improve that a bit + colors"]}, {"x": 159.0, "y": 341.0, "text": "color tone", "font_size": 8, "color": "rgb(162, 218, 55)", "hover_html": "<b>Keyword:</b> color tone<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. ChatGPT always yellowish To be honest, I'm not a<br>like this yellow effect being everywhere.<br>2. Yes, I totally agree with you! I can't wait to see<br>it once they fix this !<br>3. 4o is insane, I just hate the yellowish filter it<br>applies to 99% of the images.", "raw_count": 4, "samples": ["ChatGPT always yellowish To be honest, I'm not a like this yellow effect being everywhere.", "Yes, I totally agree with you! I can't wait to see it once they fix this !", "4o is insane, I just hate the yellowish filter it applies to 99% of the images."]}, {"x": 304.5, "y": 117.0, "text": "hallucination", "font_size": 8, "color": "rgb(117, 208, 84)", "hover_html": "<b>Keyword:</b> hallucination<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. It hallucinates a bit but overall I like it.<br>2. yea it hallucinates and create a lot of new things<br>not present in the image<br>3. The bird got fatter and it hallucinated a new<br>branch.", "raw_count": 4, "samples": ["It hallucinates a bit but overall I like it.", "yea it hallucinates and create a lot of new things not present in the image", "The bird got fatter and it hallucinated a new branch."]}, {"x": 118.5, "y": 32.0, "text": "design accuracy", "font_size": 7, "color": "rgb(44, 115, 142)", "hover_html": "<b>Keyword:</b> design accuracy<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. This is like those cargo cult tribesman who build<br>helicopter sculptures and think that because it's<br>shaped like one, it will fly like one. Source: I'm<br>a mechanical engineer, this is embarrassing to<br>look at, this drawing makes no sense, you<br>accomplished nothing.<br>2. yeah the drawing like many others, makes sense on<br>the surface, but the deeper i look into it the<br>more problems i find.... like what the heck is 3<br>and 4???<br>3. Again, missed my point. Correct structures could<br>easily be made if you show a sketch or even<br>properly explain the diagrams. Point is, these<br>models can perform design processes and generate<br>properly. Again, that was done with zero attempt<br>at accuracy lol", "raw_count": 4, "samples": ["This is like those cargo cult tribesman who build helicopter sculptures and think that because it's shaped like one, it will fly like one. Source: I'm a mechanical engineer, this is embarrassing to look at, this drawing makes no sense, you accomplished nothing.", "yeah the drawing like many others, makes sense on the surface, but the deeper i look into it the more problems i find.... like what the heck is 3 and 4???", "Again, missed my point. Correct structures could easily be made if you show a sketch or even properly explain the diagrams. Point is, these models can perform design processes and generate properly. Again, that was done with zero attempt at accuracy lol"]}, {"x": 9.5, "y": 180.0, "text": "color shift", "font_size": 7, "color": "rgb(59, 82, 139)", "hover_html": "<b>Keyword:</b> color shift<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Why did the image become green again halfway<br>through?<br>2. And it never modify only one part of the image,<br>it's always changing a bit something everywhere...<br>Inpainting with other solutions have still good<br>life !!<br>3. Yes. Also have noticed a degradation in quality...<br>introduction of graininess. Not just when editing<br>the same images but continuing to do work in the<br>same chat.", "raw_count": 4, "samples": ["Why did the image become green again halfway through?", "And it never modify only one part of the image, it's always changing a bit something everywhere... Inpainting with other solutions have still good life !!", "Yes. Also have noticed a degradation in quality... introduction of graininess. Not just when editing the same images but continuing to do work in the same chat."]}, {"x": 132.0, "y": 222.5, "text": "facial expression", "font_size": 6, "color": "rgb(59, 187, 117)", "hover_html": "<b>Keyword:</b> facial expression<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Looks great! But, that slight facial expression<br>shift could be the make it or break it decision.<br>2. See in the original his facial expressions has a<br>slight sly smile/smirk look? The Ai<br>upscaled/improved image has a more bright beaming<br>smiling.  Just saying it didn\u2019t keep the exact<br>original look; but, it is definitely a HUGE<br>improvement in quality!<br>3. i had to prompt it a bit more, because it didn't<br>get the facial expression right (img1) and than it<br>tried to add hair to baby's head (img2) but it's<br>much faster than gpt-4o and you can iterate faster<br>and get similar results faster!", "raw_count": 4, "samples": ["Looks great! But, that slight facial expression shift could be the make it or break it decision.", "See in the original his facial expressions has a slight sly smile/smirk look? The Ai upscaled/improved image has a more bright beaming smiling.\n\nJust saying it didn\u2019t keep the exact original look; but, it is definitely a HUGE improvement in quality!", "i had to prompt it a bit more, because it didn't get the facial expression right (img1) and than it tried to add hair to baby's head (img2)\nbut it's much faster than gpt-4o and you can iterate faster and get similar results faster!"]}, {"x": 23.5, "y": 148.5, "text": "blending", "font_size": 6, "color": "rgb(94, 201, 98)", "hover_html": "<b>Keyword:</b> blending<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. B with A color grading so the mascot doesn\u2019t blend<br>with the background<br>2. B makes the little guy stand out more.<br>3. A, the second picture blends in with the<br>background", "raw_count": 4, "samples": ["B with A color grading so the mascot doesn\u2019t blend with the background", "B makes the little guy stand out more.", "A, the second picture blends in with the background"]}, {"x": 57.0, "y": 88.5, "text": "detail fidelity", "font_size": 6, "color": "rgb(72, 40, 120)", "hover_html": "<b>Keyword:</b> detail fidelity<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Man, this is the absolute state of walking in<br>downtown Denver, except the homeless folks looks<br>10x more ragged than this generated guy.<br>2. \"Keep every label, detail, and color 100% intact.\"<br>3. The instructions were the same for  @grok   and<br>Chat GPT, however you failed. I even broke it down<br>for you  @grok", "raw_count": 4, "samples": ["Man, this is the absolute state of walking in downtown Denver, except the homeless folks looks 10x more ragged than this generated guy.", "\"Keep every label, detail, and color 100% intact.\"", "The instructions were the same for \n@grok\n  and Chat GPT, however you failed. I even broke it down for you \n@grok"]}, {"x": 153.5, "y": 87.5, "text": "coherency", "font_size": 6, "color": "rgb(68, 1, 84)", "hover_html": "<b>Keyword:</b> coherency<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. And imo its interesting to see how these models<br>slowly lose coherency as they're fed with their<br>own data repeatedly and not knowing what to do<br>with it.<br>2. And I mean, it is expected to devolve because the<br>AI output will look shittier and lose information<br>when compared to the original pic. What we are<br>seeing is chat GPT having less and less coherent<br>data to work it by each frame.<br>3. The first iteration looks like the exact same<br>image, no changes at all, the next couple are of<br>poor quality, and the rest don\u2019t even resemble the<br>original image.", "raw_count": 4, "samples": ["And imo its interesting to see how these models slowly lose coherency as they're fed with their own data repeatedly and not knowing what to do with it.", "And I mean, it is expected to devolve because the AI output will look shittier and lose information when compared to the original pic. What we are seeing is chat GPT having less and less coherent data to work it by each frame.", "The first iteration looks like the exact same image, no changes at all, the next couple are of poor quality, and the rest don\u2019t even resemble the original image."]}, {"x": 66.0, "y": 116.0, "text": "color contrast", "font_size": 6, "color": "rgb(57, 85, 140)", "hover_html": "<b>Keyword:</b> color contrast<br><b>Count:</b> 4<br><br><b>Samples:</b><br>1. Dude that looks terrible<br>2. Well, the direction is good overall, but the<br>bright, pastel colors contrast poorly with white<br>text.<br>3. Probably giving everything a 1px black border or<br>drop shadow will make it 10x better", "raw_count": 4, "samples": ["Dude that looks terrible", "Well, the direction is good overall, but the bright, pastel colors contrast poorly with white text.", "Probably giving everything a 1px black border or drop shadow will make it 10x better"]}, {"x": 314.0, "y": 239.0, "text": "ghibli style", "font_size": 5, "color": "rgb(32, 146, 140)", "hover_html": "<b>Keyword:</b> ghibli style<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. better face but less \"ghibli\". The monster driving<br>the car in image 1 is a great idea.<br>2. this must be the grimmest and darkest<br>ghiblification I've ever seen<br>3. what's with the gloom and doom? the aesthetic is<br>cool and gives off Dark City 1998 vibes, but<br>certainly grim.", "raw_count": 3, "samples": ["better face but less \"ghibli\". The monster driving the car in image 1 is a great idea.", "this must be the grimmest and darkest ghiblification I've ever seen", "what's with the gloom and doom? the aesthetic is cool and gives off Dark City 1998 vibes, but certainly grim."]}, {"x": 121.0, "y": 20.0, "text": "counting", "font_size": 5, "color": "rgb(53, 95, 141)", "hover_html": "<b>Keyword:</b> counting<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. I think counting what is already in a picture<br>(hard) and generating N instances (easy) require<br>completely different intelligence for genAI. So,<br>this test doesn't prove it can count. Counting<br>items in an existing image requires memory (to<br>keep track of what is already counted)<br>2. The Result? Almost comical failure. Despite clear<br>instructions, the AI consistently gave me a rod<br>with only 9 units. Not 8, not 11, always 9.<br>Precision seems hard for AI, even with simple<br>counting!<br>3. Tried tweaking wording, stressing the count again.<br>Still 9 cubes. It seemed stuck. Is '10' somehow<br>problematic for this visual task in its training?<br>Time for a wild experiment... What if I asked for<br>more?", "raw_count": 3, "samples": ["I think counting what is already in a picture (hard) and generating N instances (easy) require completely different intelligence for genAI. So, this test doesn't prove it can count. Counting items in an existing image requires memory (to keep track of what is already counted)", "The Result? Almost comical failure. Despite clear instructions, the AI consistently gave me a rod with only 9 units. Not 8, not 11, always 9. Precision seems hard for AI, even with simple counting!", "Tried tweaking wording, stressing the count again. Still 9 cubes. It seemed stuck. Is '10' somehow problematic for this visual task in its training? Time for a wild experiment... What if I asked for more?"]}, {"x": 311.0, "y": 232.5, "text": "detail", "font_size": 5, "color": "rgb(69, 53, 129)", "hover_html": "<b>Keyword:</b> detail<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. I like the first one better. The detail is more<br>crisp, and the colors are consistent, and the<br>picture just looks better, to me.<br>2. It got close.<br>3. It's great at editing existing images and prompt<br>adherence; it's great because it fills a gap where<br>the available--but far better--image generators<br>are weak. GPT-4o native image generation is far<br>less detailed and imaginative than Midjourney<br>overall.", "raw_count": 3, "samples": ["I like the first one better. The detail is more crisp, and the colors are consistent, and the picture just looks better, to me.", "It got close.", "It's great at editing existing images and prompt adherence; it's great because it fills a gap where the available--but far better--image generators are weak. GPT-4o native image generation is far less detailed and imaginative than Midjourney overall."]}, {"x": 333.0, "y": 174.5, "text": "annotation", "font_size": 5, "color": "rgb(226, 228, 24)", "hover_html": "<b>Keyword:</b> annotation<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Btw even Gemini 2.0 flash is bad at it<br>2. Pretty sure these models are trained more on real<br>life images than technical diagrams...<br>3. This is something that AI will fix next. Now that<br>text and image consistency is better than ever.<br>Now it needs to know where to apply an edit<br>exactly. It will only get better from here.", "raw_count": 3, "samples": ["Btw even Gemini 2.0 flash is bad at it", "Pretty sure these models are trained more on real life images than technical diagrams...", "This is something that AI will fix next. Now that text and image consistency is better than ever. Now it needs to know where to apply an edit exactly. It will only get better from here."]}, {"x": 92.0, "y": 306.0, "text": "style rigidity", "font_size": 5, "color": "rgb(34, 168, 132)", "hover_html": "<b>Keyword:</b> style rigidity<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. It\u2019s really really stuck in one style.  Even when<br>you do something to make it unique like this, it\u2019s<br>like I can see the HOME style behind it.<br>2. yes, and that is very annoying - i don't want to<br>be just a clone (being just a clown i'm ok with it<br>)<br>3. Gpt is great for promoting and mocking ideas. But<br>comfyui simply allows for more malleability", "raw_count": 3, "samples": ["It\u2019s really really stuck in one style.\n\nEven when you do something to make it unique like this, it\u2019s like I can see the HOME style behind it.", "yes, and that is very annoying - i don't want to be just a clone (being just a clown i'm ok with it )", "Gpt is great for promoting and mocking ideas. But comfyui simply allows for more malleability"]}, {"x": 212.0, "y": 273.0, "text": "access", "font_size": 5, "color": "rgb(208, 225, 28)", "hover_html": "<b>Keyword:</b> access<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. The result is non-deterministic. A more general<br>solution is to analyze output itself not probable<br>output for given input. You could however<br>prefilter for obvious copyright issues like the<br>mention of Simpsons. But still, a more generalized<br>solution would be to analyze the output.<br>2. At this point you may be thinking, \u201cThis is so<br>stupid. If I want to see Harry Styles, why not<br>just use Google Image Search?\u201d  Great idea \u2014<br>that\u2019s even faster:<br>3. He says he can't do it Simpsons style.", "raw_count": 3, "samples": ["The result is non-deterministic. A more general solution is to analyze output itself not probable output for given input. You could however prefilter for obvious copyright issues like the mention of Simpsons. But still, a more generalized solution would be to analyze the output.", "At this point you may be thinking, \u201cThis is so stupid. If I want to see Harry Styles, why not just use Google Image Search?\u201d\n\nGreat idea \u2014 that\u2019s even faster:", "He says he can't do it Simpsons style."]}, {"x": 92.5, "y": 178.5, "text": "text errors", "font_size": 5, "color": "rgb(60, 79, 138)", "hover_html": "<b>Keyword:</b> text errors<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. lotta text in this is messed up tho -- it feels<br>like i'm stuck between 4o & Dall-e 3<br>2. It\u2019s spelled in an alien language<br>3. Here's Gemini Imagen 4's attempt.  Not too bad.<br>But the sign texts have more errors.", "raw_count": 3, "samples": ["lotta text in this is messed up tho -- it feels like i'm stuck between 4o & Dall-e 3", "It\u2019s spelled in an alien language", "Here's Gemini Imagen 4's attempt.\n\nNot too bad. But the sign texts have more errors."]}, {"x": 30.0, "y": 158.5, "text": "3D realism", "font_size": 5, "color": "rgb(221, 227, 24)", "hover_html": "<b>Keyword:</b> 3D realism<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. This is not a 3D render, it's a simulation of a 3D<br>render. You can't change the angle, the lighting,<br>the thickness of the extrude or the bevel. It<br>can't be animated. There is no actual geometry. It<br>made a decent looking jpeg based off the stolen<br>work of other 3D artists.<br>2. Now add the generated one in Kling and ask it to<br>animate it, and you just did in 20 mins what<br>otherwise would take a lot of man hours. I'll<br>still prefer it as a real 3D and the option to rig<br>and animate it however is necessary, but these<br>tools are getting scary good by the day.<br>3. I agree that the icon was generated, but you don\u2019t<br>have the raw 3D project to make precise<br>adjustments.", "raw_count": 3, "samples": ["This is not a 3D render, it's a simulation of a 3D render. You can't change the angle, the lighting, the thickness of the extrude or the bevel. It can't be animated. There is no actual geometry. It made a decent looking jpeg based off the stolen work of other 3D artists.", "Now add the generated one in Kling and ask it to animate it, and you just did in 20 mins what otherwise would take a lot of man hours. I'll still prefer it as a real 3D and the option to rig and animate it however is necessary, but these tools are getting scary good by the day.", "I agree that the icon was generated, but you don\u2019t have the raw 3D project to make precise adjustments."]}, {"x": 236.0, "y": 166.0, "text": "prompt comprehension", "font_size": 5, "color": "rgb(132, 212, 75)", "hover_html": "<b>Keyword:</b> prompt comprehension<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Hahah, indeed. Literally every contemporary model<br>does better than MJ on prompt comprehension.<br>(Seedream3, Imagen3, Reve, HiDream).<br>2. i yearn for the day we get the artistic style and<br>speed of midjourney with the prompt understanding<br>of 4o<br>3. and they all look kinda meh unfortunately,<br>whichever side can figure out how to combine the<br>two will win", "raw_count": 3, "samples": ["Hahah, indeed. Literally every contemporary model does better than MJ on prompt comprehension. (Seedream3, Imagen3, Reve, HiDream).", "i yearn for the day we get the artistic style and speed of midjourney with the prompt understanding of 4o", "and they all look kinda meh unfortunately, whichever side can figure out how to combine the two will win"]}, {"x": 33.0, "y": 253.5, "text": "inspiration", "font_size": 5, "color": "rgb(71, 45, 123)", "hover_html": "<b>Keyword:</b> inspiration<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. There shouldn't even be a debate. It's at best a<br>silly distraction. It's not art. It's CERTAINLY<br>not art on the level of anything Ghibli has ever<br>done.<br>2. This is not what inspiration is.<br>3. How could anyone use AI-generated Studio Ghibli<br>art? That's just terrible.", "raw_count": 3, "samples": ["There shouldn't even be a debate. It's at best a silly distraction. It's not art. It's CERTAINLY not art on the level of anything Ghibli has ever done.", "This is not what inspiration is.", "How could anyone use AI-generated Studio Ghibli art? That's just terrible."]}, {"x": 152.5, "y": 81.0, "text": "layout preservation", "font_size": 5, "color": "rgb(68, 57, 131)", "hover_html": "<b>Keyword:</b> layout preservation<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. It doesn't look bad but besides the ridiculous<br>amount of time that chatgpt takes to generate a<br>single image(>10x more than roomremake) which is<br>already a game changer, it did not keep the<br>original layout of the room, creating a kitchen in<br>the back with another living room (??)<br>2. This breaks the whole purpose of redesigning a<br>room, since you obviously want to keep the real<br>layout of your place<br>3. Of course, this is just a quick test, but so far<br>my conclusion is that you can save time and money<br>(since roomremake is cheaper than GPT-4o) by using<br>roomremake if your goal is to redesign a room.", "raw_count": 3, "samples": ["It doesn't look bad but besides the ridiculous amount of time that chatgpt takes to generate a single image(>10x more than roomremake) which is already a game changer, it did not keep the original layout of the room, creating a kitchen in the back with another living room (??)", "This breaks the whole purpose of redesigning a room, since you obviously want to keep the real layout of your place", "Of course, this is just a quick test, but so far my conclusion is that you can save time and money (since roomremake is cheaper than GPT-4o) by using roomremake if your goal is to redesign a room."]}, {"x": 324.0, "y": 139.0, "text": "weaponization", "font_size": 5, "color": "rgb(39, 126, 142)", "hover_html": "<b>Keyword:</b> weaponization<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. What can we infer from this? -ChatGPT was trained<br>to use sea-lioning as a tactic to use against<br>critics  -ChatGPT was trained to use swarming<br>tactics to silence critics  -ChatGPT was trained<br>to use coordinated responses to discredit critics<br>So that\u2019s relatively disturbing.<br>2. It\u2019s not surprising, since it was trained on our<br>data, and these are some of the most common<br>tactics used in disinformation and harassment<br>campaigns. But one would hope that ChatGPT would<br>not be allowed to just ingest that toxic behavior<br>and reproduce it.<br>3. Also, based on its depiction here, it appears that<br>ChatGPT has learned (been trained) to weaponize<br>fact-checking, which again is not surprising but<br>is also probably among the most disturbing<br>revelations I have come across in a while.", "raw_count": 3, "samples": ["What can we infer from this?\n-ChatGPT was trained to use sea-lioning as a tactic to use against critics \n-ChatGPT was trained to use swarming tactics to silence critics \n-ChatGPT was trained to use coordinated responses to discredit critics\n\nSo that\u2019s relatively disturbing.", "It\u2019s not surprising, since it was trained on our data, and these are some of the most common tactics used in disinformation and harassment campaigns. But one would hope that ChatGPT would not be allowed to just ingest that toxic behavior and reproduce it.", "Also, based on its depiction here, it appears that ChatGPT has learned (been trained) to weaponize fact-checking, which again is not surprising but is also probably among the most disturbing revelations I have come across in a while."]}, {"x": 52.0, "y": 220.5, "text": "self-awareness", "font_size": 5, "color": "rgb(74, 193, 109)", "hover_html": "<b>Keyword:</b> self-awareness<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. It\u2019s not really. This kind of output isn\u2019t my<br>favorite. My favorite is when it surprises me.<br>It\u2019s very \u2026 Greek. Roman. Which isn\u2019t old at all.<br>Very new.<br>2. An LLM wouldn\u2019t think this way if it was given<br>leeway to think the weight itself dynamically,<br>would it? That would be the actual expression of<br>this. This is like humans.<br>3. LLM sad but LLM can\u2019t feel sad", "raw_count": 3, "samples": ["It\u2019s not really. This kind of output isn\u2019t my favorite. My favorite is when it surprises me. It\u2019s very \u2026 Greek. Roman. Which isn\u2019t old at all. Very new.", "An LLM wouldn\u2019t think this way if it was given leeway to think the weight itself dynamically, would it? That would be the actual expression of this. This is like humans.", "LLM sad but LLM can\u2019t feel sad"]}, {"x": 238.5, "y": 121.0, "text": "missing details", "font_size": 5, "color": "rgb(47, 180, 124)", "hover_html": "<b>Keyword:</b> missing details<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Yeah, it looks really good. But I think it still<br>misses something, look at this one, there are some<br>shadows and smaller details that are just no there<br>yet in AI images.<br>2. If the chatgpt result is the second image, then it<br>missed quite a lot haha<br>3. took a few tries for first and had to ask it to<br>fix the 2nd but still impressed (scared?)", "raw_count": 3, "samples": ["Yeah, it looks really good. But I think it still misses something, look at this one, there are some shadows and smaller details that are just no there yet in AI images.", "If the chatgpt result is the second image, then it missed quite a lot haha", "took a few tries for first and had to ask it to fix the 2nd but still impressed (scared?)"]}, {"x": 243.0, "y": 32.0, "text": "color accuracy", "font_size": 5, "color": "rgb(37, 132, 142)", "hover_html": "<b>Keyword:</b> color accuracy<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Why isn't the death star gold then ?<br>2. Because it needs the camouflage \u2014 but it also<br>comes in dictator chic for birthday parades.<br>3. I wish the \u201cphoto\u201d would have gotten the eye<br>colors and the reflected yellow-green color<br>correct.", "raw_count": 3, "samples": ["Why isn't the death star gold then ?", "Because it needs the camouflage \u2014 but it also comes in dictator chic for birthday parades.", "I wish the \u201cphoto\u201d would have gotten the eye colors and the reflected yellow-green color correct."]}, {"x": 251.0, "y": 282.0, "text": "text quality", "font_size": 5, "color": "rgb(48, 105, 142)", "hover_html": "<b>Keyword:</b> text quality<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. What prompt did you use for Kling. Though the text<br>for the product is not looking good<br>2. MidJourney v7 is miles ahead of 6.1 and is even<br>more realistic than GPT-4o, but it fails to create<br>text as nicely as ChatGPT, which I used in the<br>free version.<br>3. Yeah my generations look just okay and the text is<br>not right", "raw_count": 3, "samples": ["What prompt did you use for Kling. Though the text for the product is not looking good", "MidJourney v7 is miles ahead of 6.1 and is even more realistic than GPT-4o, but it fails to create text as nicely as ChatGPT, which I used in the free version.", "Yeah my generations look just okay and the text is not right"]}, {"x": 312.5, "y": 224.0, "text": "muscle growth", "font_size": 5, "color": "rgb(33, 165, 133)", "hover_html": "<b>Keyword:</b> muscle growth<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Sounds like the gym's bouncer said, \"No gains for<br>you!\"<br>2. Watching that thing makes me feel like I'm<br>hallucinating a lot!<br>3. The first guy is skinny? Never felt so bad about<br>myself ha!", "raw_count": 3, "samples": ["Sounds like the gym's bouncer said, \"No gains for you!\"", "Watching that thing makes me feel like I'm hallucinating a lot!", "The first guy is skinny? Never felt so bad about myself ha!"]}, {"x": 60.5, "y": 290.0, "text": "sharpness", "font_size": 5, "color": "rgb(62, 76, 138)", "hover_html": "<b>Keyword:</b> sharpness<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Yo, why aren\u2019t my pics poppin\u2019 as crisp and real<br>as yours? I\u2019m a Plus user too!  It sucks<br>2. bro, your prompt is fire, but why do my Plus plan<br>app images look trash? I try the free version and<br>get dope results like yours. What\u2019s the deal?<br>3. I think when writing the prompt, you can specify<br>to sharpen the images a bit more and create them<br>based on specific references. Generally, for these<br>types of prompts, I do many trials until I reach<br>the form I want.", "raw_count": 3, "samples": ["Yo, why aren\u2019t my pics poppin\u2019 as crisp and real as yours? I\u2019m a Plus user too!  It sucks", "bro, your prompt is fire, but why do my Plus plan app images look trash? I try the free version and get dope results like yours. What\u2019s the deal?", "I think when writing the prompt, you can specify to sharpen the images a bit more and create them based on specific references. Generally, for these types of prompts, I do many trials until I reach the form I want."]}, {"x": 217.5, "y": 204.0, "text": "refinement", "font_size": 5, "color": "rgb(72, 27, 109)", "hover_html": "<b>Keyword:</b> refinement<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Honestly not really. This took 4 tries, and I gave<br>up because it was good enough.<br>2. I spent 10 hours yesterday playing around with it<br>has a tough time refining. But it was addictive. A<br>lot of great output.<br>3. These are awesome. I did a few similar to this in<br>MidJourney V6. It did struggle with movie titles.<br>Definitely got to give these ago in 4.0 a go soon.", "raw_count": 3, "samples": ["Honestly not really. This took 4 tries, and I gave up because it was good enough.", "I spent 10 hours yesterday playing around with it has a tough time refining. But it was addictive. A lot of great output.", "These are awesome. I did a few similar to this in MidJourney V6. It did struggle with movie titles. Definitely got to give these ago in 4.0 a go soon."]}, {"x": 55.0, "y": 69.5, "text": "color bias", "font_size": 5, "color": "rgb(63, 71, 136)", "hover_html": "<b>Keyword:</b> color bias<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. There's likely a yellow bias in the training that<br>becomes apparent when continuously feeding the<br>output back into the input over and over (which I<br>suspect is being done internally), compounding the<br>bias. Of course, this is speculation (as all<br>explanations on here are).<br>2. this is kinda close, the more accurate explanation<br>is that ironically the trend of \"ghibli\"-fying<br>images involved adding a piss yellow filter over<br>it people made so many studio ghibli ai images<br>that it flooded the internet and as a result<br>flooded ai training data lmao<br>3. OpenAI hasn\u2019t trained a new image gen since 4o<br>image gen released. Even during the studio ghibli<br>trend, the images were still overly yellow.", "raw_count": 3, "samples": ["There's likely a yellow bias in the training that becomes apparent when continuously feeding the output back into the input over and over (which I suspect is being done internally), compounding the bias. Of course, this is speculation (as all explanations on here are).", "this is kinda close, the more accurate explanation is that ironically the trend of \"ghibli\"-fying images involved adding a piss yellow filter over it\npeople made so many studio ghibli ai images that it flooded the internet and as a result flooded ai training data lmao", "OpenAI hasn\u2019t trained a new image gen since 4o image gen released. Even during the studio ghibli trend, the images were still overly yellow."]}, {"x": 235.0, "y": 235.5, "text": "detail differentiation", "font_size": 5, "color": "rgb(31, 162, 135)", "hover_html": "<b>Keyword:</b> detail differentiation<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. I don\u2019t see any difference<br>2. very clear difference between low and medium but<br>nothing between medium and high but this is also<br>probably a terrible demo a more complex prompt<br>should be used<br>3. So it just decreased the roughness of the material<br>by 0.2", "raw_count": 3, "samples": ["I don\u2019t see any difference", "very clear difference between low and medium but nothing between medium and high but this is also probably a terrible demo a more complex prompt should be used", "So it just decreased the roughness of the material by 0.2"]}, {"x": 60.5, "y": 178.0, "text": "latency", "font_size": 5, "color": "rgb(127, 211, 78)", "hover_html": "<b>Keyword:</b> latency<br><b>Count:</b> 3<br><br><b>Samples:</b><br>1. Nah, I\u2019ve trimmed it. It\u2019s pretty slow.<br>2. Hand was also adjusted)<br>3. The latency is so bad.", "raw_count": 3, "samples": ["Nah, I\u2019ve trimmed it. It\u2019s pretty slow.", "Hand was also adjusted)", "The latency is so bad."]}, {"x": 118.5, "y": 317.5, "text": "authenticity", "font_size": 4, "color": "rgb(50, 182, 122)", "hover_html": "<b>Keyword:</b> authenticity<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Using a fake image to portray something is not an<br>effective way to instill belief in that thing.  It<br>tends one to think fake image, fake belief.<br>2. Before generating an image of a Houri as you<br>described, I\u2019d like to confirm: your prompt<br>mentions 'large, wide black eyes with white<br>irises' and 'around 11 years old,' but traditional<br>Islamic texts describe Houris with black irises<br>and white sclera, aged", "raw_count": 2, "samples": ["Using a fake image to portray something is not an effective way to instill belief in that thing.  It tends one to think fake image, fake belief.", "Before generating an image of a Houri as you described, I\u2019d like to confirm: your prompt mentions 'large, wide black eyes with white irises' and 'around 11 years old,' but traditional Islamic texts describe Houris with black irises and white sclera, aged"]}, {"x": 62.5, "y": 172.5, "text": "foam, structure", "font_size": 4, "color": "rgb(35, 136, 142)", "hover_html": "<b>Keyword:</b> foam, structure<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. They both get the foam wrong<br>2. Consistency still feels like the hardest thing to<br>crack for most visual models. Even when it gets<br>the style right, the structure falls apart.<br>Curious what you think the missing link<br>is...probably some combo of architecture /<br>training data?", "raw_count": 2, "samples": ["They both get the foam wrong", "Consistency still feels like the hardest thing to crack for most visual models. Even when it gets the style right, the structure falls apart. Curious what you think the missing link is...probably some combo of architecture / training data?"]}, {"x": 164.0, "y": 274.5, "text": "yellow tint", "font_size": 4, "color": "rgb(72, 23, 105)", "hover_html": "<b>Keyword:</b> yellow tint<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. wasn't there a rumor suggesting something went<br>'wrong' with training, & a ton of their images had<br>a yellow-ish tint, so they leaned into ghibli<br>2. Haha. I still don't know why they add yellow to<br>everything, maybe it's a hidden watermark", "raw_count": 2, "samples": ["wasn't there a rumor suggesting something went 'wrong' with training, & a ton of their images had a yellow-ish tint, so they leaned into ghibli", "Haha. I still don't know why they add yellow to everything, maybe it's a hidden watermark"]}, {"x": 62.0, "y": 235.5, "text": "inconsistencies", "font_size": 4, "color": "rgb(59, 81, 139)", "hover_html": "<b>Keyword:</b> inconsistencies<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. small small inconsistencies but this is amazing<br>2. However, limitations include inconsistencies and<br>potential for artifacts.", "raw_count": 2, "samples": ["small small inconsistencies but this is amazing", "However, limitations include inconsistencies and potential for artifacts."]}, {"x": 121.5, "y": 102.5, "text": "reflection", "font_size": 4, "color": "rgb(70, 48, 126)", "hover_html": "<b>Keyword:</b> reflection<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. I don\u2019t think GPT-4o does well with mirrors  it\u2019s<br>a very cool and artistic pic tho, makes me look<br>like my reflection is doing something different.<br>2. but the reflection??? jeez", "raw_count": 2, "samples": ["I don\u2019t think GPT-4o does well with mirrors  it\u2019s a very cool and artistic pic tho, makes me look like my reflection is doing something different.", "but the reflection??? jeez"]}, {"x": 128.5, "y": 170.5, "text": "logos and visuals", "font_size": 4, "color": "rgb(59, 81, 139)", "hover_html": "<b>Keyword:</b> logos and visuals<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Not perfect (logos have been changed slightly in<br>places, numerical values slightly different) but<br>an incredible improvement.<br>2. Good if you look from 2 meters away", "raw_count": 2, "samples": ["Not perfect (logos have been changed slightly in places, numerical values slightly different) but an incredible improvement.", "Good if you look from 2 meters away"]}, {"x": 165.5, "y": 185.0, "text": "ingredient accuracy", "font_size": 4, "color": "rgb(127, 211, 78)", "hover_html": "<b>Keyword:</b> ingredient accuracy<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Almost there (a few minor errors)! Give it a few<br>years .. the system will be fast enough for near<br>real-time interactive feedback; many use cases for<br>this beyond cooking.<br>2. ChatGPT-4o hallucinated tomatoes in the recipe<br>though", "raw_count": 2, "samples": ["Almost there (a few minor errors)! Give it a few years .. the system will be fast enough for near real-time interactive feedback; many use cases for this beyond cooking.", "ChatGPT-4o hallucinated tomatoes in the recipe though"]}, {"x": 299.0, "y": 277.5, "text": "labeling", "font_size": 4, "color": "rgb(71, 19, 101)", "hover_html": "<b>Keyword:</b> labeling<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. But when we used the same prompt from the original<br>post to try and duplicate the labeled cell, we<br>repeatedly came up short. Despite trying various<br>prompting strategies, it could never accurately<br>create a diagram of a cell and label the parts.<br>2. We ran the same prompt through multiple generators<br>with poor results. While image generators are<br>improving quickly, it's clear they still have a<br>lot of room for improvement.", "raw_count": 2, "samples": ["But when we used the same prompt from the original post to try and duplicate the labeled cell, we repeatedly came up short. Despite trying various prompting strategies, it could never accurately create a diagram of a cell and label the parts.", "We ran the same prompt through multiple generators with poor results. While image generators are improving quickly, it's clear they still have a lot of room for improvement."]}, {"x": 144.5, "y": 273.0, "text": "style bias", "font_size": 4, "color": "rgb(236, 229, 27)", "hover_html": "<b>Keyword:</b> style bias<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. I just wish the ghibli style wasn't giving us<br>white people features (small nose, etc)<br>2. exactly. tried forcing monogatari a lot and it's<br>of no use. might as well name it gpt4g instead.", "raw_count": 2, "samples": ["I just wish the ghibli style wasn't giving us white people features (small nose, etc)", "exactly. tried forcing monogatari a lot and it's of no use. might as well name it gpt4g instead."]}, {"x": 38.5, "y": 252.0, "text": "height manipulation", "font_size": 4, "color": "rgb(68, 57, 131)", "hover_html": "<b>Keyword:</b> height manipulation<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. That's not what i asked<br>2. I'm sorry, I didn't fully understand your request<br>to modify the image by making the girl short and<br>the guys tall. Current AI image editing tools,<br>like those based on GPT-4o, can handle many tasks<br>but often struggle with precise, context-specific<br>edits, fulfilling only about", "raw_count": 2, "samples": ["That's not what i asked", "I'm sorry, I didn't fully understand your request to modify the image by making the girl short and the guys tall. Current AI image editing tools, like those based on GPT-4o, can handle many tasks but often struggle with precise, context-specific edits, fulfilling only about"]}, {"x": 75.0, "y": 230.5, "text": "symbolism", "font_size": 4, "color": "rgb(165, 219, 54)", "hover_html": "<b>Keyword:</b> symbolism<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. maybe the black heart might be more symbolic and<br>accurate.<br>2. The figure needs to square the circle. The human<br>connecting the divine and the mundane. Damn cool<br>already though.", "raw_count": 2, "samples": ["maybe the black heart might be more symbolic and accurate.", "The figure needs to square the circle. The human connecting the divine and the mundane. Damn cool already though."]}, {"x": 25.5, "y": 238.5, "text": "regression", "font_size": 4, "color": "rgb(44, 115, 142)", "hover_html": "<b>Keyword:</b> regression<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Seriously! They were using a state-of-the-art open<br>source model called Flux, and then introduced<br>their own bad model and never improved it. What's<br>the point?!<br>2. I think the new grok model was better at image gen<br>than flux, but it just seems really bad now that<br>GPT-4o image gen came out.", "raw_count": 2, "samples": ["Seriously! They were using a state-of-the-art open source model called Flux, and then introduced their own bad model and never improved it. What's the point?!", "I think the new grok model was better at image gen than flux, but it just seems really bad now that GPT-4o image gen came out."]}, {"x": 66.0, "y": 204.5, "text": "contrast", "font_size": 4, "color": "rgb(208, 225, 28)", "hover_html": "<b>Keyword:</b> contrast<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. If you mind a cookie from me  The contrast in the<br>white rectangle  Can you increase it<br>2. low contrast can be due to over-processing or poor<br>optimization", "raw_count": 2, "samples": ["If you mind a cookie from me \nThe contrast in the white rectangle \nCan you increase it", "low contrast can be due to over-processing or poor optimization"]}, {"x": 217.5, "y": 226.5, "text": "style,concept", "font_size": 4, "color": "rgb(39, 126, 142)", "hover_html": "<b>Keyword:</b> style,concept<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Disappointed: artistic draws still lag behind<br>Midjourney.<br>2. Midjourney's notes are nonsense.", "raw_count": 2, "samples": ["Disappointed: artistic draws still lag behind Midjourney.", "Midjourney's notes are nonsense."]}, {"x": 284.5, "y": 163.0, "text": "story fidelity", "font_size": 4, "color": "rgb(31, 158, 137)", "hover_html": "<b>Keyword:</b> story fidelity<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Here\u2019s the ending, which I thought captured the<br>content well but is missing the sense of doom felt<br>by the protagonist<br>2. and here it\u2019s completely hallucinated a scene that<br>was never in the story", "raw_count": 2, "samples": ["Here\u2019s the ending, which I thought captured the content well but is missing the sense of doom felt by the protagonist", "and here it\u2019s completely hallucinated a scene that was never in the story"]}, {"x": 240.5, "y": 221.5, "text": "product placement", "font_size": 4, "color": "rgb(66, 64, 134)", "hover_html": "<b>Keyword:</b> product placement<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. And then back to photoshop to tone down the amber<br>glow of 4o<br>2. Mj still gives me the best results in terms of<br>aesthetics, but it\u2019s not great for placing<br>products. Do you have any suggestions?", "raw_count": 2, "samples": ["And then back to photoshop to tone down the amber glow of 4o", "Mj still gives me the best results in terms of aesthetics, but it\u2019s not great for placing products. Do you have any suggestions?"]}, {"x": 249.5, "y": 275.5, "text": "style switching", "font_size": 4, "color": "rgb(32, 163, 134)", "hover_html": "<b>Keyword:</b> style switching<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. It's particularly frustrating when you're trying<br>to switch styles - like from line drawing or<br>sketch, to more photoreal.<br>2. The results are not the same image at all!", "raw_count": 2, "samples": ["It's particularly frustrating when you're trying to switch styles - like from line drawing or sketch, to more photoreal.", "The results are not the same image at all!"]}, {"x": 28.5, "y": 142.5, "text": "multi-subject", "font_size": 4, "color": "rgb(72, 22, 104)", "hover_html": "<b>Keyword:</b> multi-subject<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. been trying to figure out how to do this for my<br>piddy and wolf crew, but it just looks like shit<br>every time lol<br>2. That\u2019s strange. Maybe the model struggles when you<br>have multiple figures on one base image? Might<br>have to convert them individually?", "raw_count": 2, "samples": ["been trying to figure out how to do this for my piddy and wolf crew, but it just looks like shit every time lol", "That\u2019s strange. Maybe the model struggles when you have multiple figures on one base image? Might have to convert them individually?"]}, {"x": 191.0, "y": 33.5, "text": "quality degradation", "font_size": 4, "color": "rgb(202, 225, 31)", "hover_html": "<b>Keyword:</b> quality degradation<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Support says there is no problem but quality is<br>10x worst than before and even the playground has<br>issues<br>2. This is something they do regularly that only<br>power users will notice. They launch a model at<br>full power to allow the hype train to give them<br>free advertising, then once they've gotten the<br>exposure they want, they optimize it which<br>drastically lowers quality. I noticed this", "raw_count": 2, "samples": ["Support says there is no problem but quality is 10x worst than before and even the playground has issues", "This is something they do regularly that only power users will notice. They launch a model at full power to allow the hype train to give them free advertising, then once they've gotten the exposure they want, they optimize it which drastically lowers quality. I noticed this"]}, {"x": 103.5, "y": 275.5, "text": "object accuracy", "font_size": 4, "color": "rgb(229, 228, 25)", "hover_html": "<b>Keyword:</b> object accuracy<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. I'm not trying to be mean, but It's a freaking<br>black triangle with three lights at each corner.<br>What service were u using that couldn't get this<br>one, right? lol<br>2. No center light?", "raw_count": 2, "samples": ["I'm not trying to be mean, but It's a freaking black triangle with three lights at each corner. What service were u using that couldn't get this one, right? lol", "No center light?"]}, {"x": 187.0, "y": 177.5, "text": "representation", "font_size": 4, "color": "rgb(72, 26, 108)", "hover_html": "<b>Keyword:</b> representation<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. I asked 'why drawing a female doctor?' The answer<br>was<br>2. Then I followed with the question 'If you were<br>mindful of female representation, how about<br>representation of 'colored' doctors as obviously<br>your default pic was 'white doctor'? \u2026 and the<br>answer was :", "raw_count": 2, "samples": ["I asked 'why drawing a female doctor?' The answer was", "Then I followed with the question 'If you were mindful of female representation, how about representation of 'colored' doctors as obviously your default pic was 'white doctor'? \u2026 and the answer was :"]}, {"x": 239.5, "y": 115.5, "text": "impossible object", "font_size": 4, "color": "rgb(41, 121, 142)", "hover_html": "<b>Keyword:</b> impossible object<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. my favorite image generator, midjourney, can't get<br>a penrose triangle correct [left] but if you feed<br>it the stock image and ask it to retexture, then<br>it tends to do well with the geometry of the<br>diagram [right]<br>2. i think there's a lot we (or at least i) don't<br>understand about how image models handle local<br>versus global geometry. midjourney is clearly<br>getting a lot of the segmentation correct, and yet<br>it cannot generate a penrose triangle on its own<br>(yet)...", "raw_count": 2, "samples": ["my favorite image generator, midjourney, can't get a penrose triangle correct [left] but if you feed it the stock image and ask it to retexture, then it tends to do well with the geometry of the diagram [right]", "i think there's a lot we (or at least i) don't understand about how image models handle local versus global geometry. midjourney is clearly getting a lot of the segmentation correct, and yet it cannot generate a penrose triangle on its own (yet)..."]}, {"x": 204.5, "y": 19.0, "text": "aesthetic", "font_size": 4, "color": "rgb(59, 81, 139)", "hover_html": "<b>Keyword:</b> aesthetic<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. An original design, no doubt, but I\u2019m not sure<br>brands would sell much with such a demonic<br>aesthetic<br>2. Looks like a 80s ad that was designed in 2025, by<br>a program.  Zero 80s aesthetic here.", "raw_count": 2, "samples": ["An original design, no doubt, but I\u2019m not sure brands would sell much with such a demonic aesthetic", "Looks like a 80s ad that was designed in 2025, by a program.\n\nZero 80s aesthetic here."]}, {"x": 136.0, "y": 13.5, "text": "badges", "font_size": 4, "color": "rgb(72, 29, 111)", "hover_html": "<b>Keyword:</b> badges<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Look at the badges!<br>2. Proof: \u201cThought for 7 seconds\u201d", "raw_count": 2, "samples": ["Look at the badges!", "Proof: \u201cThought for 7 seconds\u201d"]}, {"x": 136.0, "y": 75.5, "text": "feature naming", "font_size": 4, "color": "rgb(31, 149, 139)", "hover_html": "<b>Keyword:</b> feature naming<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Hah, even GPT-4o doesn't know the right name for<br>its own feature!<br>2. I pressed it asking what it's called, and it said<br>that gpt4-o is multimodal and has the image<br>generation natively.  Only asking for the image<br>was I able to get it to name itself.", "raw_count": 2, "samples": ["Hah, even GPT-4o doesn't know the right name for its own feature!", "I pressed it asking what it's called, and it said that gpt4-o is multimodal and has the image generation natively.\n\nOnly asking for the image was I able to get it to name itself."]}, {"x": 142.0, "y": 241.0, "text": "eyes", "font_size": 4, "color": "rgb(55, 184, 120)", "hover_html": "<b>Keyword:</b> eyes<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Maybe I'm biassed, but for me, these generated<br>thumbnails are always missing something. It's<br>eyes. They look soulless (of course!)<br>2. It\u2019s a game changer but it\u2019s always screwing with<br>the eyes", "raw_count": 2, "samples": ["Maybe I'm biassed, but for me, these generated thumbnails are always missing something. It's eyes. They look soulless (of course!)", "It\u2019s a game changer but it\u2019s always screwing with the eyes"]}, {"x": 130.0, "y": 195.5, "text": "normalcy", "font_size": 4, "color": "rgb(42, 119, 142)", "hover_html": "<b>Keyword:</b> normalcy<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. why is she still so scary<br>2. we will know we\u2019ve hit ASI if it can then make her<br>less crazy", "raw_count": 2, "samples": ["why is she still so scary", "we will know we\u2019ve hit ASI if it can then make her less crazy"]}, {"x": 111.5, "y": 89.5, "text": "wireframe accuracy", "font_size": 4, "color": "rgb(36, 134, 142)", "hover_html": "<b>Keyword:</b> wireframe accuracy<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. this is not gatekeeping this is just stating a<br>fact. the wireframe turns into monster truck<br>drawings lol this is not a high quality accurate<br>depiction of a wireframe. you are not correct and<br>any 3D artist will tell you this.<br>2. yes it would be a texture in most cases. If it was<br>modeled it would not be a line drawing as it is<br>here. there is also a cylinder, a basic 3D<br>primitive that isn't modeled well. at the end of<br>the day though it's a 2D image of a wireframe and<br>it doesnt really mean anything.", "raw_count": 2, "samples": ["this is not gatekeeping this is just stating a fact. the wireframe turns into monster truck drawings lol this is not a high quality accurate depiction of a wireframe. you are not correct and any 3D artist will tell you this.", "yes it would be a texture in most cases. If it was modeled it would not be a line drawing as it is here. there is also a cylinder, a basic 3D primitive that isn't modeled well. at the end of the day though it's a 2D image of a wireframe and it doesnt really mean anything."]}, {"x": 273.5, "y": 265.5, "text": "imperfection", "font_size": 4, "color": "rgb(69, 4, 87)", "hover_html": "<b>Keyword:</b> imperfection<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. it's got a small imperfection on its right hand<br>but I'm only trying to show first prompts and not<br>finished products -- this is insane<br>2. Pre launch imperfect snoozies. Priceless", "raw_count": 2, "samples": ["it's got a small imperfection on its right hand but I'm only trying to show first prompts and not finished products -- this is insane", "Pre launch imperfect snoozies. Priceless"]}, {"x": 207.0, "y": 263.5, "text": "rind", "font_size": 4, "color": "rgb(72, 27, 109)", "hover_html": "<b>Keyword:</b> rind<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Done in Copilot. Seems to not include the rind.<br>2. Thank you very much. Thank you for your prompt. I<br>was hoping my peacock would have the seeds just<br>like that. They just added in more things you can<br>do in Copilot. Anime style is one I tried. I might<br>revisit this prompt and see if I can get some<br>rind. Here is the anime style.", "raw_count": 2, "samples": ["Done in Copilot. Seems to not include the rind.", "Thank you very much. Thank you for your prompt. I was hoping my peacock would have the seeds just like that. They just added in more things you can do in Copilot. Anime style is one I tried. I might revisit this prompt and see if I can get some rind. Here is the anime style."]}, {"x": 112.0, "y": 325.5, "text": "prompt details", "font_size": 4, "color": "rgb(71, 46, 124)", "hover_html": "<b>Keyword:</b> prompt details<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. I didn't get exactly what the prompt wanted but I<br>thought they turned out pretty cute so I thought<br>I'd share<br>2. The first one is more in line with the prompt, but<br>they are all so cute!", "raw_count": 2, "samples": ["I didn't get exactly what the prompt wanted but I thought they turned out pretty cute so I thought I'd share", "The first one is more in line with the prompt, but they are all so cute!"]}, {"x": 207.5, "y": 339.5, "text": "text details", "font_size": 4, "color": "rgb(176, 221, 47)", "hover_html": "<b>Keyword:</b> text details<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. It seems like it adds one string of text correctly<br>(like the counter strike screenshot) and the rest<br>is wrong. For instance in the fallout one the map<br>goes from South, to South West, to North without<br>West-West.<br>2. I mean technically it changes some of the text.<br>People will have to build a tool that can change<br>small details easily for this to work for<br>designers.", "raw_count": 2, "samples": ["It seems like it adds one string of text correctly (like the counter strike screenshot) and the rest is wrong. For instance in the fallout one the map goes from South, to South West, to North without West-West.", "I mean technically it changes some of the text. People will have to build a tool that can change small details easily for this to work for designers."]}, {"x": 306.5, "y": 260.5, "text": "sliced styles", "font_size": 4, "color": "rgb(38, 130, 142)", "hover_html": "<b>Keyword:</b> sliced styles<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. It has more trouble understanding as you increase<br>the number of slices...<br>2. It can't seem to understand the idea beyond<br>that...", "raw_count": 2, "samples": ["It has more trouble understanding as you increase the number of slices...", "It can't seem to understand the idea beyond that..."]}, {"x": 125.5, "y": 177.5, "text": "memory bleed", "font_size": 4, "color": "rgb(37, 171, 130)", "hover_html": "<b>Keyword:</b> memory bleed<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. As I feared, 4o is errantly using images from old<br>chats as references for new image requests in new<br>chats now. This memory is anything but intelligent<br>(for image generation)<br>2. Absolutely worse, and also has the potential of<br>poisoning further chats if it previously started<br>hallucinating.", "raw_count": 2, "samples": ["As I feared, 4o is errantly using images from old chats as references for new image requests in new chats now. This memory is anything but intelligent (for image generation)", "Absolutely worse, and also has the potential of poisoning further chats if it previously started hallucinating."]}, {"x": 293.5, "y": 194.0, "text": "missing object", "font_size": 4, "color": "rgb(31, 151, 139)", "hover_html": "<b>Keyword:</b> missing object<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. heh yeah the one eyed snake is still hidden in<br>most pictures<3<br>2. I'd definitely buy one! But where is the bicycle?", "raw_count": 2, "samples": ["heh yeah the one eyed snake is still hidden in most pictures<3", "I'd definitely buy one! But where is the bicycle?"]}, {"x": 193.5, "y": 172.5, "text": "mockup usability", "font_size": 4, "color": "rgb(53, 95, 141)", "hover_html": "<b>Keyword:</b> mockup usability<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. I\u2019ll be doing a-lot of this in the coming months.<br>Now just need Ai to be good at placing logos and<br>designs on mockups and this would be a game<br>changer.<br>2. Good platform but please make a secondary way<br>apart from connection nodes. Many professional<br>creatives ran away from 3d suites because of this<br>complex pipeline style. Image drag and drop would<br>be cool, also zoom is crazy hard to control when<br>just wanting a simple output", "raw_count": 2, "samples": ["I\u2019ll be doing a-lot of this in the coming months. Now just need Ai to be good at placing logos and designs on mockups and this would be a game changer.", "Good platform but please make a secondary way apart from connection nodes. Many professional creatives ran away from 3d suites because of this complex pipeline style. Image drag and drop would be cool, also zoom is crazy hard to control when just wanting a simple output"]}, {"x": 305.5, "y": 267.5, "text": "translation", "font_size": 4, "color": "rgb(57, 85, 140)", "hover_html": "<b>Keyword:</b> translation<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. First, here's the output with gemini:<br>Original/'translated' Quite bad.<br>2. Here's grok Original/'translated' Quite<br>hallucinated!", "raw_count": 2, "samples": ["First, here's the output with gemini: Original/'translated' Quite bad.", "Here's grok Original/'translated' Quite hallucinated!"]}, {"x": 82.5, "y": 71.5, "text": "cartoonish", "font_size": 4, "color": "rgb(30, 157, 137)", "hover_html": "<b>Keyword:</b> cartoonish<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Yeah it\u2019s annoying because they actually look<br>decent when I run it on the ChatGPT app but as<br>soon as I go to the API, even on high quality, I<br>get cartoons.<br>2. I've been wondering the same thing! Can't get<br>images to look real real.", "raw_count": 2, "samples": ["Yeah it\u2019s annoying because they actually look decent when I run it on the ChatGPT app but as soon as I go to the API, even on high quality, I get cartoons.", "I've been wondering the same thing! Can't get images to look real real."]}, {"x": 337.5, "y": 201.0, "text": "overinterpretation", "font_size": 4, "color": "rgb(64, 70, 136)", "hover_html": "<b>Keyword:</b> overinterpretation<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Yeah, I will say one of my complaints about Grok<br>is that it tries to be smarter by using previous<br>information and \u201creading between the lines\u201d when<br>you\u2019re literally just trying to tell it to do<br>something and there\u2019s nothing deeper behind it.<br>2. exactly. it does too much lol. it almost always<br>takes creative liberties when generating photos, &<br>that\u2019s often not useful.", "raw_count": 2, "samples": ["Yeah, I will say one of my complaints about Grok is that it tries to be smarter by using previous information and \u201creading between the lines\u201d when you\u2019re literally just trying to tell it to do something and there\u2019s nothing deeper behind it.", "exactly. it does too much lol. it almost always takes creative liberties when generating photos, & that\u2019s often not useful."]}, {"x": 308.5, "y": 255.5, "text": "facial coherence", "font_size": 4, "color": "rgb(32, 146, 140)", "hover_html": "<b>Keyword:</b> facial coherence<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Here is a sample response. My face was recreated,<br>and it is unable to preserve my facial details.<br>2. The uncanny valley hits different in AI generated<br>content. Still better than most NFT pfps tho", "raw_count": 2, "samples": ["Here is a sample response. My face was recreated, and it is unable to preserve my facial details.", "The uncanny valley hits different in AI generated content. Still better than most NFT pfps tho"]}, {"x": 179.5, "y": 270.0, "text": "context-limitation", "font_size": 4, "color": "rgb(72, 33, 115)", "hover_html": "<b>Keyword:</b> context-limitation<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. Did a talk/editing article on this. It only works<br>in contexts with a rich range of 1: aesthetics<br>(with their own political/historical<br>entanglements) 2: symbolism. Otherwise it's cringe<br>(pic rel).<br>2. Yeah for quick memes it\u2019s too slow", "raw_count": 2, "samples": ["Did a talk/editing article on this. It only works in contexts with a rich range of 1: aesthetics (with their own political/historical entanglements) 2: symbolism. Otherwise it's cringe (pic rel).", "Yeah for quick memes it\u2019s too slow"]}, {"x": 314.5, "y": 214.5, "text": "color", "font_size": 4, "color": "rgb(71, 17, 100)", "hover_html": "<b>Keyword:</b> color<br><b>Count:</b> 2<br><br><b>Samples:</b><br>1. would you tell it to remove the yellow<br>2. They need to figure out the wam hue thing. Would<br>be so much more powerful if every image didn\u2019t<br>look like it had an orange filter on. This model\u2019s<br>weakness is truly expressive color. Cc @sama", "raw_count": 2, "samples": ["would you tell it to remove the yellow", "They need to figure out the wam hue thing. Would be so much more powerful if every image didn\u2019t look like it had an orange filter on. This model\u2019s weakness is truly expressive color. Cc @sama"]}];
            var firstKeyword = "identity";
            var originalColors = ["rgb(33, 166, 133)", "rgb(63, 72, 137)", "rgb(31, 159, 136)", "rgb(30, 155, 138)", "rgb(55, 90, 140)", "rgb(66, 190, 113)", "rgb(63, 72, 137)", "rgb(72, 33, 115)", "rgb(35, 169, 131)", "rgb(31, 153, 138)", "rgb(72, 29, 111)", "rgb(38, 173, 129)", "rgb(66, 65, 134)", "rgb(105, 205, 91)", "rgb(61, 77, 138)", "rgb(37, 133, 142)", "rgb(45, 113, 142)", "rgb(68, 191, 112)", "rgb(36, 170, 131)", "rgb(69, 56, 130)", "rgb(61, 188, 116)", "rgb(62, 76, 138)", "rgb(42, 120, 142)", "rgb(218, 227, 25)", "rgb(63, 71, 136)", "rgb(200, 224, 32)", "rgb(70, 48, 126)", "rgb(57, 85, 140)", "rgb(46, 111, 142)", "rgb(32, 146, 140)", "rgb(162, 218, 55)", "rgb(117, 208, 84)", "rgb(44, 115, 142)", "rgb(59, 82, 139)", "rgb(59, 187, 117)", "rgb(94, 201, 98)", "rgb(72, 40, 120)", "rgb(68, 1, 84)", "rgb(57, 85, 140)", "rgb(32, 146, 140)", "rgb(53, 95, 141)", "rgb(69, 53, 129)", "rgb(226, 228, 24)", "rgb(34, 168, 132)", "rgb(208, 225, 28)", "rgb(60, 79, 138)", "rgb(221, 227, 24)", "rgb(132, 212, 75)", "rgb(71, 45, 123)", "rgb(68, 57, 131)", "rgb(39, 126, 142)", "rgb(74, 193, 109)", "rgb(47, 180, 124)", "rgb(37, 132, 142)", "rgb(48, 105, 142)", "rgb(33, 165, 133)", "rgb(62, 76, 138)", "rgb(72, 27, 109)", "rgb(63, 71, 136)", "rgb(31, 162, 135)", "rgb(127, 211, 78)", "rgb(50, 182, 122)", "rgb(35, 136, 142)", "rgb(72, 23, 105)", "rgb(59, 81, 139)", "rgb(70, 48, 126)", "rgb(59, 81, 139)", "rgb(127, 211, 78)", "rgb(71, 19, 101)", "rgb(236, 229, 27)", "rgb(68, 57, 131)", "rgb(165, 219, 54)", "rgb(44, 115, 142)", "rgb(208, 225, 28)", "rgb(39, 126, 142)", "rgb(31, 158, 137)", "rgb(66, 64, 134)", "rgb(32, 163, 134)", "rgb(72, 22, 104)", "rgb(202, 225, 31)", "rgb(229, 228, 25)", "rgb(72, 26, 108)", "rgb(41, 121, 142)", "rgb(59, 81, 139)", "rgb(72, 29, 111)", "rgb(31, 149, 139)", "rgb(55, 184, 120)", "rgb(42, 119, 142)", "rgb(36, 134, 142)", "rgb(69, 4, 87)", "rgb(72, 27, 109)", "rgb(71, 46, 124)", "rgb(176, 221, 47)", "rgb(38, 130, 142)", "rgb(37, 171, 130)", "rgb(31, 151, 139)", "rgb(53, 95, 141)", "rgb(57, 85, 140)", "rgb(30, 157, 137)", "rgb(64, 70, 136)", "rgb(32, 146, 140)", "rgb(72, 33, 115)", "rgb(71, 17, 100)"];
            
            // State management
            var lockedWord = null;
            var isLocked = true;
            
            // Create the plot
            var plot = document.getElementById('wordcloud-div');
            Plotly.newPlot(plot, figure.data, figure.layout, {displayModeBar: false, responsive: true});
            
            // Function to update word colors
            function updateWordColors(lockedWordText) {
                var newColors = originalColors.slice();
                
                if (lockedWordText) {
                    var lockedIndex = wordData.findIndex(function(w) { return w.text === lockedWordText; });
                    if (lockedIndex !== -1) {
                        newColors[lockedIndex] = '#cc4125ff';  // Bright red for locked word
                    }
                }
                
                Plotly.restyle(plot, {'textfont.color': [newColors]}, [0]);
            }
            
            // Function to display word details
            function displayWordDetails(word) {
                var content = '<div class="word-name">' + word.text + " (" + word.raw_count + ")" + '</div>';
                content += '<div class="samples-section">';
                content += 'Community Feedback:<br><br>';
                
                if (word.samples && word.samples.length > 0) {
                    word.samples.forEach(function(sample, i) {
                        content += '<div class="sample-item">';
                        content += '<span class="sample-number">' + (i + 1) + '.</span>';
                        content += sample;
                        content += '</div>';
                    });
                } else {
                    content += '<div class="placeholder">No samples available</div>';
                }
                
                content += '</div>';
                
                document.getElementById('tooltip-content').innerHTML = content;
            }
            
            // Function to find word by text
            function findWordByText(text) {
                return wordData.find(function(w) { return w.text === text; });
            }
            
            // Initialize with first keyword
            if (firstKeyword) {
                document.getElementById('keyword-select').value = firstKeyword;
                var firstWord = findWordByText(firstKeyword);
                if (firstWord) {
                    displayWordDetails(firstWord);
                    lockedWord = firstWord;
                    updateWordColors(firstKeyword);
                }
            }
            
            // Handle dropdown change
            document.getElementById('keyword-select').addEventListener('change', function(e) {
                var selectedWord = e.target.value.trim();
                var tooltipContent = document.getElementById('tooltip-content');
                
                if (!selectedWord) {
                    lockedWord = null;
                    isLocked = false;
                    updateWordColors(null);
                    tooltipContent.innerHTML = '<div class="placeholder">Select a keyword to view examples</div>';
                    return;
                }

                var word = findWordByText(selectedWord);
                if (word) {
                    lockedWord = word;
                    isLocked = true;
                    displayWordDetails(word);
                    updateWordColors(selectedWord);
                }
            });
            
            // Handle click events for locking and color change
            plot.on('plotly_click', function(data) {
                if (data.points && data.points.length > 0) {
                    var pointIndex = data.points[0].pointIndex;
                    var word = wordData[pointIndex];
                    
                    // Toggle lock
                    if (isLocked && lockedWord && lockedWord.text === word.text) {
                        // Unlock
                        isLocked = false;
                        lockedWord = null;
                        updateWordColors(null);
                        document.getElementById('keyword-select').value = '';
                    } else {
                        // Lock on new word
                        isLocked = true;
                        lockedWord = word;
                        displayWordDetails(word);
                        updateWordColors(word.text);
                        document.getElementById('keyword-select').value = word.text;
                    }
                }
            });
        </script>
    </body>
    </html>
    